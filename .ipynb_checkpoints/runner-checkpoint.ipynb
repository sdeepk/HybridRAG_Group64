{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ed3d77-8264-44b8-865b-60abbf06e307",
   "metadata": {},
   "source": [
    "## Group No \n",
    " \n",
    "## Group Member Names:\n",
    "|| BITS ID | Name | Contribution |\n",
    "| :------: | :---------------- | :------ | :----: |\n",
    "| 1. | 2024aa05354| ANKIT GUPTA     | 100%\n",
    "| 2. | 2024aa05010 | Himanshu Arora | 100%\n",
    "| 3. | TODO | TODO  | 100%\n",
    "| 4. | TODO | TODO | 100%\n",
    "| 5. | TODO | TODO | 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62430148-5677-4dfa-b26b-3ad145e80cd9",
   "metadata": {},
   "source": [
    "<H1> Dataset Requirements </H1>\n",
    "<H2>Objective<H2>\n",
    "\n",
    "    Build a Hybrid Retrieval-Augmented Generation (RAG) system combining dense vector retrieval, sparse keyword retrieval (BM25), and Reciprocal Rank Fusion (RRF) to answer questions from 500 Wikipedia articles. Evaluate using an automated framework with 100 generated questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16b2b1-5ed6-4c3f-8d17-1fed3f7bf051",
   "metadata": {},
   "source": [
    "<h2>Installing required Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71191e7-e05c-41c6-8fb0-8b28774d0498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.0 MB 3.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 3.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.0 MB 3.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.9/12.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.7/12.0 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.5/12.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.0/12.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.5/12.0 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/12.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.8/12.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.6/12.0 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.4/12.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.0/1.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.7 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.8/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.6/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece, safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.36.0 safetensors-0.7.0 sentencepiece-0.2.1 tokenizers-0.22.2 transformers-4.57.6\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c8431fa-6f27-4098-bf12-3def50040561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.4.1-cp39-abi3-win_amd64.whl.metadata (7.3 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.3-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (4.14.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.23.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (0.22.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading pypika-0.50.0-py2.py3-none-any.whl.metadata (51 kB)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (1.73.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (0.16.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-35.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.11.5-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=24.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.33.4-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.7.1-cp312-cp312-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading chromadb-1.4.1-cp39-abi3-win_amd64.whl (21.4 MB)\n",
      "   ---------------------------------------- 0.0/21.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/21.4 MB 3.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.3/21.4 MB 3.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.8/21.4 MB 3.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.4/21.4 MB 3.1 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.9/21.4 MB 2.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 3.7/21.4 MB 3.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 4.5/21.4 MB 3.0 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 5.0/21.4 MB 3.0 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 5.8/21.4 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 6.6/21.4 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 7.3/21.4 MB 3.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 8.1/21.4 MB 3.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 8.9/21.4 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 10.0/21.4 MB 3.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 10.7/21.4 MB 3.5 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 11.8/21.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 12.8/21.4 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 13.6/21.4 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 14.7/21.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 15.5/21.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 16.3/21.4 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 17.3/21.4 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 18.1/21.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 18.6/21.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 19.4/21.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 20.2/21.4 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 20.7/21.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 21.4/21.4 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl (150 kB)\n",
      "Downloading build-1.4.0-py3-none-any.whl (24 kB)\n",
      "Downloading kubernetes-35.0.0-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.2.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.23.2-cp312-cp312-win_amd64.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/13.5 MB 3.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.3/13.5 MB 3.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.1/13.5 MB 3.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.9/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.7/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.5/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.2/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.0/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.8/13.5 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.3/13.5 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.9/13.5 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.9/13.5 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.7/13.5 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.5/13.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.5/13.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.3/13.5 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.1/13.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.5/13.5 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "Downloading orjson-3.11.5-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading pybase64-1.4.3-cp312-cp312-win_amd64.whl (35 kB)\n",
      "Downloading pypika-0.50.0-py2.py3-none-any.whl (60 kB)\n",
      "Downloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading httptools-0.7.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Downloading protobuf-6.33.4-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading watchfiles-1.1.1-cp312-cp312-win_amd64.whl (288 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pypika, durationpy, pyreadline3, pyproject_hooks, pybase64, protobuf, orjson, oauthlib, mmh3, importlib-resources, httptools, bcrypt, backoff, watchfiles, uvicorn, requests-oauthlib, posthog, opentelemetry-proto, opentelemetry-api, humanfriendly, googleapis-common-protos, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, coloredlogs, opentelemetry-sdk, onnxruntime, sentence-transformers, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "Successfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.4.0 chromadb-1.4.1 coloredlogs-15.0.1 durationpy-0.10 googleapis-common-protos-1.72.0 httptools-0.7.1 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-35.0.0 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 orjson-3.11.5 posthog-5.4.0 protobuf-6.33.4 pybase64-1.4.3 pypika-0.50.0 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 sentence-transformers-5.2.0 uvicorn-0.40.0 watchfiles-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\stanh\\anaconda3\\Lib\\site-packages\\~crypt'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.4 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.0.0 which is incompatible.\n",
      "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9625a9-3b1f-43a0-bbdc-3edc22c6981a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics\n",
      "Category  Physics\n",
      "Titles  ['Physics', 'Atominstitute', 'Edge states', 'Electrostatic solitary wave', 'Frenesy (physics)', 'Haloscope (physics)', 'HUN-REN Wigner Research Centre for Physics', 'Joaquim da Costa Ribeiro', 'Missile lofting', 'Modern physics', 'Naïve physics', 'Negative air ions', 'Nottingham effect', 'Nucleation', 'Perfect fluid', 'Physics of Life', 'Plasmaron', 'Quasi-isodynamic stellarator', 'SDSS J120136.02+300305.5', 'Shockwave cosmology', 'Surface stress', 'Synchronous lateral excitation', 'Thermal energy', 'Toroidal solenoid', 'Wohlfarth Lectureship']\n",
      "\n",
      "Chemistry\n",
      "Category  Chemistry\n",
      "Titles  ['Chemistry', 'Actinide chemistry', 'Allotropy', 'Alloy', 'Amateur chemistry', 'Arens–van Dorp synthesis', 'Astrochemistry', 'Atmospheric chemistry', 'Atom', 'Biliprotein', 'Bioconcentration', 'Biophysical chemistry', 'Bittern (salt)', 'Building block (chemistry)', 'C1 chemistry', 'Calconcarboxylic acid', 'Carbodiphosphoranes', 'Carryover effect', 'The central science', 'Charged aerosol detector', 'Chemical bath deposition', 'Chemical biology', 'Chemical compound', 'Chemical element', 'Chemical equation', 'Chemical free', 'Chemical library', 'Chemical reaction', 'Chemical similarity', 'Chemical state', 'Chemical synthesis', 'Chemical technologist', 'Chemophobia', 'Chemoproteomics', 'Chirgwin–Coulson weights', 'Chromogen', 'Clandestine chemistry', 'Clay chemistry', 'Colloidal probe technique', 'Compliance constants', 'Compound Interest (website)', 'Congener (chemistry)', 'Cononsolvency', 'Core–shell semiconductor nanocrystal', 'Corrosion inhibitors for the petroleum industry', 'Crossover experiment (chemistry)', 'Crystal chemistry', 'Crystallography', 'Cyclosiloxane', 'Dark oxygen', 'Decay technique', 'DePriester chart', 'Direct reduction', 'Double layer forces', 'Electroconductive carbon black', 'Electrolysed water', 'Energy-rich species', 'Environmental chemistry', 'Equivalent weight', 'Estimated maximum possible concentration', 'Eutectic system', 'Field effect (chemistry)', 'Forensic chemistry', 'Free element', 'Geometry index', 'Gilchrist–Thomas process', 'Glossary of chemistry terms', 'C-glycosyl tryptophan', 'Green chemistry', 'Grupo Fertiberia', 'InChIKey', 'Intrinsic DNA fluorescence', 'Ioliomics', 'Landolt–Börnstein', 'Lewis acidic antimony compounds', 'Liquid nitrogen wash', 'Magnetochemistry', 'Mathematical chemistry', 'Mechanochemistry', 'Mental gland', 'Metal assisted chemical etching', 'Methane functionalization', 'Micro-X-ray fluorescence', 'Microfluidic cell culture', 'Microscale chemistry', 'Microsegregation', 'Mixed oxidant', 'Mixture', 'Molecule', 'Nanochemistry', 'Natural product', 'Negative air ions', 'Nuclear chemistry', 'Nucleation', 'Organic chemistry', 'Organolithium chemistry', 'Particle aggregation', 'Particle deposition', 'Random sequential adsorption', 'Phenol sulfur transferase deficiency', 'Philosophy of chemistry', 'Phosphorimidazolide', 'Photochemistry', 'Photopharmacology', 'Phytochemistry', 'Pressure-induced hydration', 'Probico', 'Radioanalytical chemistry', 'Rayleigh fractionation', 'Scale (chemistry)', 'School of Molecular Sciences', 'Shape of the atomic nucleus', 'Single-cell nanoencapsulation', \"Sinner's circle\", 'Soft chemistry', 'Solid-state electrolyte', 'Sonochemistry', 'Stable phosphorus radicals', 'Stereochemistry', 'Structural chemistry', 'Superelectrophilic anion', 'Superplasticizer', 'Supramolecular chemistry', 'Supramolecular coordination complex', 'Systems chemistry', 'Theoretical chemistry', 'Timeline of plastic development', 'TOP Assay', 'Triboluminescence', 'Wet chemistry']\n",
      "\n",
      "Biology\n",
      "Category  Biology\n",
      "Titles  ['Biology', 'Biologist', 'Bibliography of encyclopedias: biology', 'Bioactive terrarium', 'Bioliteracy', 'Biological constraints', 'Biology of romantic love', 'Biospeleology', 'Cancer exodus hypothesis', 'Chlororespiration', 'Dermestarium', 'Endogeny (biology)', 'Erinacin', 'Excretion', 'Functional information', 'High throughput biology', 'Interdigitation', 'Plasmagene', 'Poison exon', 'Polylecty', 'Spatial biology', 'Tokogeny', 'Universality–diversity paradigm']\n",
      "\n",
      "Mathematics\n",
      "Category  Mathematics\n",
      "Titles  ['Mathematics', 'Constructions of magic squares', 'Language of mathematics', 'Linear range', 'Linearity', 'Synthetic mathematics']\n",
      "\n",
      "Computer_science\n",
      "Category  Computer_science\n",
      "Titles  ['Computer science', 'Glossary of computer science', 'Outline of computer science', 'Agnostic (data)', 'Boolean', 'Catalytic computing', 'Computational gastronomy', 'Computer science in sport', 'Filter and refine', 'Learnable function', 'LinkML', 'List of abstractions (computer science)', 'Peripheral', 'Prefetching', 'Technology transfer in computer science', 'Thermodynamic computing', 'Transition (computer science)', 'Sara L. Uckelman']\n",
      "\n",
      "Artificial_intelligence\n",
      "Category  Artificial_intelligence\n",
      "Titles  ['Artificial intelligence', 'List of artificial intelligence journals', '2024–2026 global memory supply shortage', 'Actor-critic algorithm', 'Admissible heuristic', 'Agentive logic', '.ai', 'AI agent', 'AI alignment', 'AI anthropomorphism', 'AI browser', 'AI datacenter', 'AI literacy', 'AI nationalism', 'AI Overviews', 'AI safety', 'AI veganism', 'AI washing', 'AI-assisted software development', 'AI-complete', 'AIOps', 'Algorithmic probability', 'Ameca (robot)', 'And–or tree', 'Answer engine optimization', 'Argumentation framework', 'Artificial brain', 'Artificial consciousness', 'Artificial general intelligence', 'Timeline of artificial intelligence risks in global finance', 'Artificial intelligence and elections', 'Artificial intelligence arms race', 'Artificial intelligence controversies', 'Artificial intelligence in education', 'Artificial intelligence in physical therapy', 'Artificial intelligence in spirituality', 'Artificial intelligence in the 2024 United States presidential election', 'Artificial intelligence of things', 'Artificial intelligence optimization', 'Artificial intimacy', 'Artificial Inventor Project', 'Artificial psychology', 'Artificial reproduction', 'Artificial wisdom', 'ASR-complete', 'Attributional calculus', 'Autognostics', 'Automated machine learning', 'Automated Mathematician', 'Automated medical scribe', 'Automated negotiation', 'Autonomic networking', 'Autonomous agent', 'AZFinText', 'Bayesian programming', 'Anna Becker', 'Behavior informatics', 'Belief–desire–intention model', 'Brain technology', 'Business process automation', 'CarynAI', 'Case-based reasoning', 'CHAOS (chess)', 'Character computing', 'Class activation mapping', 'Cognitive computing', 'Cognitive Digital Network', 'Cognitive philology', 'Coherent extrapolated volition', 'Commonsense knowledge (artificial intelligence)', 'Competition in artificial intelligence', 'Computational heuristic intelligence', 'Computational humor', 'Computational intelligence', 'Computer audition', 'Concurrent MetateM', 'Connectionist expert system', 'DABUS', 'Data annotation', 'Deadbot', 'Deep Learning Anti-Aliasing', 'Deep Learning Super Sampling', 'Description logic', 'Diella (AI system)', 'Data Science and Predictive Analytics', 'Dynamic epistemic logic', 'Elements of AI', 'Embodied agent', 'Embodied cognitive science', 'Empowerment (artificial intelligence)', 'Enterprise cognitive system', 'Environmental impact of artificial intelligence', 'Epistemic modal logic', 'Ethics of artificial intelligence', 'Evolutionary developmental robotics', 'Explainable artificial intelligence', 'Extremal optimization', 'The Fable of Oscar', 'Feedback neural network', 'Fuzzy agent', \"Gabbay's separation theorem\", 'Galaxy AI', 'Game theory', 'Gender digital divide', 'Genesis Mission', 'Gibberlink', 'Gödel machine', 'GOLOG', 'Google AI Mode', 'Google Clips', 'Google Research', 'Grammar systems theory', 'Graphics processing unit', 'Hardware for artificial intelligence', 'Hello World: How to be Human in the Age of the Machine', 'Hierarchical control system', 'Histogram of oriented displacements', 'Human Problem Solving', 'Human-AI interaction', 'Human-centered AI', 'Hybrid intelligent system', 'Incremental heuristic search', 'INDIAai', 'Information space analysis', 'Intelligent agent', 'Intelligent control', 'Intelligent database', 'Intelligent decision support system', 'Intelligent word recognition', 'Intrinsic motivation (artificial intelligence)', 'Is This What We Want?', 'K-line (artificial intelligence)', 'KAoS', 'Knowledge compilation', 'Knowledge cutoff', 'Knowledge level', 'Knowledge-based configuration', 'Knowledge-based recommender system', 'Knowledge-based systems', 'Language/action perspective', 'Last Mile (artificial intelligence)', 'Learnable function', \"Liar's dividend\", 'Lifelong Planning A*', 'List of programming languages for artificial intelligence', 'Lists of open-source artificial intelligence software', 'Machine perception', 'MAUVE (metric)', 'Means–ends analysis', 'Mechanistic interpretability', 'MediSafe controversy', 'Military applications of artificial intelligence', 'Mindpixel', 'MindsDB', 'Mode collapse', 'Moral outsourcing', 'NASA AI Assisted-Air Quality Monitoring Project', 'Neural computation', 'Neural scaling law', 'Neuro-symbolic AI', 'Neurorobotics', 'No Fakes Act', 'Non-human', 'Nouvelle AI', 'Operation Serenata de Amor', 'Operational artificial intelligence', 'Organoid intelligence', 'Pattern theory', 'Pedagogical agent', 'Percept (artificial intelligence)', 'Personality computing', 'Personoid', 'Perusall', 'POP-11', 'Principle of rationality', 'Problem solving', 'Progress in artificial intelligence', 'Psychology of reasoning', 'Qloo', 'Quantum artificial life', 'Reasoning model', 'Recursive self-improvement', 'Resisting AI', 'Schema-agnostic databases', 'Self-management (computer science)', 'Singularity studies', 'Situated', 'Situated approach (artificial intelligence)', 'Smart object', 'Software agent', 'Space-based data center', 'Sparkles emoji', 'Spreading activation', 'STIT logic', 'Superintelligence ban', 'Supermind AI', 'SUPS', 'Syman', 'Symbol level', 'Symbolic artificial intelligence', 'TensorFlow Hub', 'Toy problem', 'Trupeer', 'UAE Strategy for Artificial Intelligence', 'United States Tech Force', 'Universal psychometrics', 'Video Super Resolution', 'Virtual intelligence', 'Wadhwani Institute for Artificial Intelligence', 'Way of the Future', 'Weak artificial intelligence', 'Web intelligence', 'Wetware (brain)', 'Wetware computer', 'Winner-take-all in action selection', 'Workplace impact of artificial intelligence', 'Wumpus world', 'Zeuthen strategy']\n",
      "\n",
      "Machine_learning\n",
      "Category  Machine_learning\n",
      "Titles  ['Machine learning', 'Outline of machine learning', '80 Million Tiny Images', 'A Logical Calculus of the Ideas Immanent in Nervous Activity', 'Accelerated Linear Algebra', 'Action model learning', 'Active learning (machine learning)', 'Adversarial machine learning', 'AI datacenter', 'AIOps', 'AIXI', 'Algorithm selection', 'Algorithmic bias', 'Algorithmic inference', 'Anomaly detection', 'Aporia (company)', 'Apprenticeship learning', 'Artificial intelligence in hiring', 'Astrostatistics', 'Attention (machine learning)', 'Audio inpainting', 'Automated decision-making', 'Automated machine learning', 'Automation in construction', 'Bag-of-words model', 'Ball tree', 'Base rate', 'Bayesian interpretation of kernel regularization', 'Bayesian learning mechanisms', 'Bayesian optimization', 'Bayesian regret', 'Bayesian structural time series', 'Bias–variance tradeoff', 'Binary classification', 'Bioserenity', 'Bradley–Terry model', 'Category utility', 'CIML community portal', 'Claude (language model)', 'Cognitive robotics', 'Concept drift', 'Conditional random field', 'Confusion matrix', 'Contrastive Language-Image Pre-training', 'Cost-sensitive machine learning', 'Coupled pattern learner', 'Croissant (metadata format)', 'Cross-entropy method', 'Cross-validation (statistics)', 'Curse of dimensionality', 'Data augmentation', 'Data exploration', 'Data preprocessing', 'Data-driven astronomy', 'Data-driven model', 'Decision list', 'Decision tree pruning', 'Deep tomographic reconstruction', 'Developmental robotics', 'Discovery system (artificial intelligence)', 'Document classification', 'Domain adaptation', 'Double descent', 'Eager learning', 'EfficientNet', 'ELMo', 'EM algorithm and GMM model', 'Embedding (machine learning)', 'Empirical dynamic modeling', 'Empirical risk minimization', 'Energy-based model', 'Equalized odds', 'Evaluation of binary classifiers', 'Evolvability (computer science)', 'Expectation propagation', 'Explanation-based learning', 'Exploration–exploitation dilemma', 'Fairness (machine learning)', 'Feature (machine learning)', 'Feature engineering', 'Feature hashing', 'Feature learning', 'Feature scaling', 'Federated learning', 'Fine-tuning (deep learning)', 'Flow-based generative model', 'Flux (machine-learning framework)', 'Force control', 'Formal concept analysis', 'Generalized additive model for location, scale and shape', 'Generative artificial intelligence', 'Generative model', 'Geometric feature learning', 'Glossary of artificial intelligence', 'Google Colab', 'Google Research', 'Granular computing', 'Grokking (machine learning)', 'H (company)', 'H2O (software)', 'Hallucination (artificial intelligence)', 'Hidden layer', 'Hierarchical navigable small world', 'Hierarchical Risk Parity', 'Highway network', 'Hugging Face', 'Human-in-the-loop', 'Hyperparameter (machine learning)', 'Hyperparameter optimization', 'In-context learning (natural language processing)', 'Inauthentic text', 'Inception score', 'Inductive bias', 'Inductive probability', 'Inductive programming', 'Inferential theory of learning', 'Instance selection', 'Instance-based learning', 'Intelligent automation', 'Isotropic position', 'JAX (software)', 'Journal of Machine Learning Research', 'Kernel density estimation', 'Kernel embedding of distributions', 'Knowledge graph embedding', 'Knowledge integration', 'Kolmogorov-Arnold Networks', 'Labeled data', 'Lazy learning', 'Leakage (machine learning)', 'Learnable function', 'Learnable function class', 'Learning automaton', 'Learning curve (machine learning)', 'Learning rate', 'Learning to rank', 'Life-time of correlation', 'Linear predictor function', 'Linear separability', 'LLM-as-a-Judge', 'Local case-control sampling', 'Lottery ticket hypothesis', 'Lyra (codec)', 'M-theory (learning framework)', 'Machine Learning (journal)', 'Machine Learning and Knowledge Extraction', 'Machine learning control', 'Machine learning in bioinformatics', 'Machine learning in earth sciences', 'Machine learning in physics', 'Machine learning in video games', 'Machine unlearning', 'Machine-learned interatomic potential', 'Manifold hypothesis', 'Manifold regularization', 'The Master Algorithm', 'Matchbox Educable Noughts and Crosses Engine', 'Matrix regularization', 'MAUVE (metric)', 'Maximum inner-product search', 'Mechanistic interpretability', 'Meta-Labeling', 'Meta-learning (computer science)', 'MLOps', 'MobileNet', 'Mode collapse', 'Model compression', 'Mountain car problem', 'Multi-armed bandit', 'Multi-task learning', 'Multimodal representation learning', 'Multimodal sentiment analysis', 'Multiple instance learning', 'Multiple-instance learning', 'Multiplicative weight update method', 'Multitask optimization', 'Multivariate adaptive regression spline', 'Native-language identification', 'Nature Machine Intelligence', 'Neural modeling fields', 'Neural network quantum states', 'Normalization (machine learning)', 'Novelty detection', 'Offline learning', 'Overfitting', 'Paraphrasing (computational linguistics)', 'Parity learning', 'Pattern language (formal languages)', 'Pattern recognition', 'Perceiver', 'PHerc. Paris. 4', 'Phi coefficient', 'Predictive learning', 'Predictive state representation', 'Preference learning', 'Prior knowledge for pattern recognition', 'Proactive learning', 'Proaftn', 'Probabilistic numerics', 'Probability matching', 'Product of experts', 'Products and applications of OpenAI', 'Programming by example', 'Prompt engineering', 'Proximal gradient methods for learning', 'Purged cross-validation', 'Pythia (machine learning)', 'Quantification (machine learning)', 'Quantum machine learning', 'Rabbit r1', 'Rademacher complexity', 'Random feature', 'Reasoning model', 'Reciprocal human machine learning', 'Relational data mining', 'Reparameterization trick', 'Right to explanation', 'Robot learning', 'Robotic process automation', 'ROCm', 'Rule induction', 'Sample complexity', 'Self-supervised learning', 'Semantic analysis (machine learning)', 'Semantic folding', 'Semi-supervised learning', 'Sequence labeling', 'Similarity learning', 'Socially assistive robot', 'Lynda Soderholm', \"Solomonoff's theory of inductive inference\", 'Spatial embedding', 'Spike-and-slab regression', 'Stability (learning theory)', 'Statistical learning theory', 'Statistical relational learning', 'Structural risk minimization', 'Structured sparsity regularization', 'Surrogate model', 'Symbolic regression', 'Tensor (machine learning)', 'TensorFlow Hub', 'Three-factor learning', 'Time series', 'Timeline of machine learning', 'Toronto Declaration', 'Transduction (machine learning)', 'Transfer learning', 'Ugly duckling theorem', 'Uncertain data', 'Under-fitting', 'Underfitting', 'Uniform convergence in probability', 'Universal portfolio algorithm', 'Upper Confidence Bound', 'VACUUM', 'Validation set', 'Vector database', 'Version space learning', 'Weak supervision', 'Weight initialization']\n",
      "\n",
      "Medicine\n",
      "Category  Medicine\n",
      "Titles  ['Medicine', 'Outline of medicine', '505(b)(2) regulatory pathway', 'Terminology of alternative medicine', 'Anti-aging medicine', 'Anti-asthmatic agent', 'Barostriction', 'Breastmilk medicine', 'Cancer exodus hypothesis', 'Clinical handover', 'Confocal endoscopy', 'Diabetes self-management', 'Dorsal pancreatic agenesis', 'Drone-Enhanced Emergency Medical Services', 'Electronic health record (Germany)', 'Follicular drug delivery', 'Intersex healthcare', 'Isotropic bands', 'KDM5C-related neurodevelopmental disorder', 'LAMA2 related congenital muscular dystrophy', 'LINKED syndrome', 'List of forms of alternative medicine', 'LY-2365109', 'Maibaron', 'Most Favored Nation Drug Pricing', \"Musicians' Medicine\", 'NAKO Health Study', 'Medical oddity', 'Pediatric endocrinology', 'Physical therapy for stroke rehabilitation', 'POCUS', 'Poison exon', 'RNU2-2 syndrome', 'RNU4-2 syndrome', 'Surgical clearance', 'Synthetic Cannabinoid Use Disorder', 'Urinary anti-infective agent', 'Vestibular paroxysmia']\n",
      "\n",
      "Psychology\n",
      "Category  Psychology\n",
      "Titles  ['Psychology', 'Outline of psychology', 'Alarmism', 'Aphantasia', 'Belief congruence', 'Binocular disparity', 'Binocular vision', 'Biology of romantic love', 'Black fatigue', 'Cognitive immunization', 'Counterphobic attitude', 'Cybersexuality', 'Double-nail illusion', 'Folk economics', 'Fragile masculinity', 'Frequency illusion', 'Human-AI interaction', 'Identity disturbance', 'Impact of the COVID-19 pandemic on time perception', 'Limerence', 'Love addiction', 'Moral emotions', 'Musical escapism', 'Obsessive love', 'Passionate and companionate love', 'Perceptual vigilance', 'Psychiatry', 'Psychologist', 'Rapture anxiety', 'Resilience week', 'Reward theory of attraction', 'Rhyme-as-reason effect', 'Social buffering', 'Synthetic thinking', 'The Chicago School of Psychology', 'Ultra-realism', 'Western esotericism and psychology']\n",
      "\n",
      "Philosophy\n",
      "Category  Philosophy\n",
      "Titles  ['Philosophy', 'Outline of philosophy', 'De ente et essentia', 'Deaf philosophy', 'Hug (folklore)', 'Singularity studies', 'Sociology of philosophy', 'Synthetic thinking', 'Universal brotherhood']\n",
      "\n",
      "Economics\n",
      "Category  Economics\n",
      "Titles  ['Economics', 'Index of economics articles', 'Outline of economics', 'Economics in film', 'Freeriding (economics)', 'Economic impact analysis']\n",
      "\n",
      "Political_science\n",
      "Category  Political_science\n",
      "Titles  ['Political science', 'Outline of political science', 'History of political science', 'Politics of memory', 'Anti-elitism', 'Anti-politics', 'Becoming Activists in Global China', 'Benevolence and the Mandate of Heaven', 'Bio-index model', 'Biology and political orientation', 'Biology and political science', 'Biopower', 'Bipolarisation', 'The Birth of Biopolitics', 'Boundary problem (political science)', 'Bureau-shaping model', 'Bureaucracy', 'Bureaucratic drift', 'Bureaucratic inertia', 'Cameral science', 'CIRI Human Rights Data Project', 'Class struggle', 'Coalition committee', 'Coercion, Capital, and European States, AD 990–1992', 'Collegial body', 'Comparative political theory', 'Comparative politics', 'Comparative Study of Electoral Systems', 'Computational politics', 'Constructivism (ethnic politics)', 'Critical juncture theory', 'Cultural imperialism', 'Deliberatorium', 'Democracy-Dictatorship Index', 'Digital era governance', 'Dual loyalty', 'East European Politics', 'Election science', 'Electoral abstention in France', 'Elite theory', 'Elitism', 'Environmental politics', 'Essex School of discourse analysis', 'The Establishment (Pakistan)', 'Ethnosymbolism', 'Exit, Voice, and Loyalty Model', 'Extended order', 'Feminist political theory', \"Foucault's lectures at the Collège de France\", 'Gateway belief model', 'Genopolitics', 'Gladstone Professor of Government', 'Global Environment and Trade Study', 'Heresthetic', 'History of terrorism', 'Horseshoe theory', 'Hybrid warfare', 'Imperial boomerang', 'India Quarterly', 'Inherent bad faith model', 'Institutional analysis', 'Institutional analysis and development framework', 'International Center for Black Sea Studies', 'International Contact Group', 'International institutes on political management', 'Issue ownership', 'Judicial Common Space', 'Latin American Public Opinion Project', 'Leadership spill', 'Legal opportunity structure', 'Level of analysis', 'Jenny M. Lewis', \"Liar's dividend\", 'Linked fate', 'Martin–Quinn score', 'Mierscheid law', 'Minimal effects hypothesis', 'Moderation theory', 'Modern Studies', 'Moral high ground', 'Multiple streams framework', 'Multistakeholder governance', 'Nationalism and gender', 'Neuropolitics', 'New generation warfare', 'NOMINATE (scaling method)', 'Notional election results', 'Nurturant parent model', 'Open government', 'The Origins of Political Order', 'Peace–industrial complex', 'Perestroika Movement (political science)', 'Policy analysis', 'Policy entrepreneur', 'Policy monitoring', 'Policy network analysis', 'Policy studies', 'Political climate', 'Political cognition', 'Political communication', 'Political decay', 'Political forecasting', 'Political groups of the European Parliament', 'Political identity', 'Political linguistics', 'Political methodology', 'Political ontology', 'Political opportunity', 'Political polarization', 'Political recruitment model', 'Political ReviewNet', 'Political stability', 'Politicisation', 'The Politics of Uncertainty', 'Post-democracy', 'Private defense agency', 'Private-collective model of innovation', 'Process tracing', 'Progress', 'Project Troy', 'Public', 'Public comment', 'Public engagement', 'Public opinion', 'Public policy', 'Public speaking', 'Regulatory capitalism', 'Revolving door effect', 'Rhetorical presidency', 'Security, Territory, Population', 'Selectorate theory', 'Self-expression values', 'Serfdom in Tibet controversy', 'Sincere favorite criterion', 'Social choice theory', 'State formation', 'Statecraft', 'Stationary bandit theory', 'Strategic urban planning', 'Strict father model', 'Systemic wars theory', 'Systems theory in political science', 'Tryphé', 'Turncoat', 'Twitter diplomacy', 'The Use of Knowledge in Society', 'Valence issue', 'Voter turnout', 'World Social Capital Monitor', 'World Values Survey']\n",
      "\n",
      "Indian_history\n",
      "Category  Indian_history\n",
      "Titles  []\n",
      "\n",
      "World_War_II\n",
      "Category  World_War_II\n",
      "Titles  ['Outline of World War II', '1945 Resko Przymorskie Dornier Do 24 crash', 'Anti-Partisan action in Srem (1944)', 'Attack on the battleship Tirpitz by submarine K-21', 'Axis powers', 'Battle of Hucisko', 'Battle of Jaktorów', 'Brickendonbury', 'Chetnik attack on the Užice Republic', 'ORP Czapla', 'Freemasonry during World War II', 'Yulii Garbuzov', 'The Ghost Division', 'James Goodwin Hall', 'John Charles Francis Holland', 'Meitei novel', 'Eric Peter Molyneux', 'Names of the Second World War', 'Naval battles of Narvik', 'Norman Crockatt', 'USCGC Northland (WPG-49)', 'Open city', 'Operation SUSSEX', 'Operation Winterende', 'Peace efforts during World War II', 'Michael Rajacich', 'ORP S-3', 'World War II', 'World War II combatives']\n",
      "\n",
      "Geography\n",
      "Category  Geography\n",
      "Titles  ['Geography', 'Outline of geography', 'Bioregion', 'Distance decay', 'Economic restructuring', 'Exploration', 'Extreme environment', 'Geo-literacy', 'Geo-replication', 'Geocriticism', 'Geographic contiguity', 'Geography of aging', 'Geohumanities', 'Governmentality', 'International date line in Judaism', 'Internet geography', 'Landlocked developing countries', 'Rank–size distribution', 'Religion and geography', 'Shoreline segmentation', 'Small Island Developing States', 'Solar equator', 'Spatial citizenship', 'Spatial justice', 'Spatial mismatch', 'Surroundings']\n",
      "\n",
      "Countries\n",
      "Category  Countries\n",
      "Titles  ['Country', 'List of country groupings', 'Gaelic Ireland', 'List of modern great powers']\n",
      "\n",
      "Architecture\n",
      "Category  Architecture\n",
      "Titles  ['Architecture', 'Index of architecture articles', '40 year structural inspections', 'Adaptive architecture', 'Anarchist architecture', 'Architectural ensemble', 'Architectural management', 'Architecture in Middle-earth', 'Architecture of Star Wars', 'Architextiles', 'Artificial intelligence in architecture', 'Atmosphere (architecture and spatial design)', 'Basket-handle arch', 'Bionic architecture', 'Building information modeling', 'Building performance simulation', 'Civil basilica', 'Conical roof', 'Coping (architecture)', 'Corporate architecture', 'Curved structures', 'Architectural drawing', 'Educational architecture', 'Ephemeral architecture', 'EUICC', 'Expression (architecture)', 'Free plan', 'Industrial architecture', 'Interactive architecture', 'Lamella (structure)', 'LGBTQ architectural contributions', 'Lifting boss', 'Membrane structure', 'Architectural model', 'Morphology (architecture and engineering)', 'Museum architecture', 'Open-source architecture', 'Organizational space', 'Overlay architecture', 'Paned window (architecture)', 'Parametric design', 'Parametric thinking', 'Performative architecture', 'Post-occupancy evaluation', 'Architectural propaganda', 'Real estate development', 'Regia (architecture)', 'Architectural reprography', 'Resilience (engineering and construction)', 'Scagliola', 'Scarab (fraternity)', 'Sciography', 'Separating arch', 'Site-specific architecture', 'Slipcover (architecture)', 'Sonata (building design software)', 'Space (architecture)', 'Space architecture', 'Standoff distance', 'Sustainable design standards', 'Architectural technology', 'Temporary appropriation', 'Totalitarian architecture', 'Traditional architecture']\n",
      "\n",
      "Music\n",
      "Category  Music\n",
      "Titles  ['Music', 'Index of music articles']\n",
      "\n",
      "Films\n",
      "Category  Films\n",
      "Titles  []\n",
      "\n",
      "Literature\n",
      "Category  Literature\n",
      "Titles  ['Literature', 'Outline of literature', 'Allusion', 'Anticipatory plagiarism', 'Bole Butake', 'Comedy of menace', 'Domestic realism', 'Film adaptation', 'Futurism (literature)', 'Indie literature', 'Intelligence literature', 'Interlingue literature', 'Literary language', 'Liberature', 'Literary dunce', 'Outdoor literature', 'Phoenician–Punic literature', 'Poetics', 'Popular history', 'Sociology of literature', 'Stylistics', 'Tears of Blood (Ratwała jaswa)', 'Western canon']\n",
      "\n",
      "Sports\n",
      "Category  Sports\n",
      "Titles  ['Sport']\n",
      "\n",
      "Cricket\n",
      "Category  Cricket\n",
      "Titles  ['Cricket', 'Batting (cricket)', 'Bowling (cricket)', 'Captain (cricket)', 'Common injuries in cricket', 'Crease (cricket)', 'Cricket ball', 'Cricket bat', 'Cricket clothing and equipment', 'Cricket field', 'Cricket pitch', 'Cricket statistics', 'Dismissal (cricket)', 'Extra (cricket)', 'Forms of cricket', 'Glossary of cricket terms', 'History of cricket', 'Innings', 'Laws of Cricket', 'Over (cricket)', 'Result (cricket)', 'Run (cricket)', 'Scorer', 'Umpire (cricket)', 'Wicket', 'Wicket-keeper', \"Women's cricket\"]\n",
      "\n",
      "Association_football\n",
      "Category  Association_football\n",
      "Titles  ['Association football', 'Outline of association football', 'Football economics', 'Football trafficking', 'Geography of association football', 'Names for association football']\n",
      "\n",
      "Astronomy\n",
      "Category  Astronomy\n",
      "Titles  ['Glossary of astronomy', 'Outline of astronomy', '96P sungrazer family', 'Alaknanda Galaxy', 'Astronomer', 'Astronomy', 'Astrotourism', 'Cygnus Molecular Nebula Complex', 'Data-driven astronomy', 'Dust astronomy', 'Elephant trunk (astronomy)', 'Exometeorology', 'Exoplanet Explorers', 'First point of Aries', 'Geodesy', 'Giuseppe Donatiello', 'Gravitational memory effect', 'Half-month', 'Harvard Plate Stacks', 'Huihui Lifa', 'IAU (1976) System of Astronomical Constants', 'Instrumental magnitude', \"Kathryn's Wheel\", 'La Sociedad Interamericana de Astronomía en la Cultura', 'List of galaxies by surface brightness', 'List of Indian astronomical treatises', 'Meitei astronomy', 'Monochrome astrophotography techniques', 'Multi-messenger astronomy', 'Jack B. Newton', 'Pale Blue Dot', 'Periodicity of solar eclipses', 'Planet Patrol (project)', 'Planetary coordinate system', 'Pycnonuclear fusion', 'Radio Galaxy Zoo', 'Regius Professor of Astronomy (Edinburgh)', 'SAGES Legacy Unifying Globulars and GalaxieS Survey', 'Pranav Sharma', 'Shockwave cosmology', 'SigMF', 'SN 1990E', 'SN 2018gv', 'Solar longitude', 'Solar radio emission', 'Songline', 'Spiral arm', 'Stellar archaeology', 'Stellar engulfment', 'Stellar flyby', 'Supergalactic plane', 'Synodic day', 'Tidal downsizing', 'Vicarious Hypothesis', 'Yajnavalkya 95 Years Cycle']\n",
      "\n",
      "Environment\n",
      "Category  Environment\n",
      "Titles  []\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fixed_count': 200,\n",
       " 'rejections': {'too_short_138': 1,\n",
       "  'too_short_137': 1,\n",
       "  'too_short_199': 1,\n",
       "  'too_short_93': 1,\n",
       "  'too_short_57': 1,\n",
       "  'too_short_66': 1,\n",
       "  'too_short_116': 1,\n",
       "  'too_short_108': 1,\n",
       "  'too_short_46': 2,\n",
       "  'empty_extract': 7,\n",
       "  'too_short_107': 1,\n",
       "  'too_short_126': 1,\n",
       "  'too_short_163': 2,\n",
       "  'too_short_71': 1,\n",
       "  'too_short_195': 1,\n",
       "  'too_short_120': 1,\n",
       "  'too_short_144': 1,\n",
       "  'too_short_117': 1,\n",
       "  'too_short_142': 1,\n",
       "  'too_short_112': 1,\n",
       "  'too_short_193': 1,\n",
       "  'too_short_110': 1,\n",
       "  'too_short_94': 1,\n",
       "  'too_short_189': 1},\n",
       " 'out': 'data/fixed_urls.json'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NOTE: Please run only once, to generate the fixed URLs\n",
    "## Prepare fixed Wikipedia URLs, covering diverse topic\n",
    "# Round-robin across categories to enforce diversity\n",
    "from src.build.build_fixed_urls import build_fixed_urls\n",
    "fixedUrl = build_fixed_urls()\n",
    "fixedUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778daa25-0a21-4d64-82b9-fe9066d418d8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_count': 300,\n",
       " 'loops': 12,\n",
       " 'rejections': {'too_short_74': 2,\n",
       "  'disambiguation': 22,\n",
       "  'too_short_31': 2,\n",
       "  'too_short_29': 4,\n",
       "  'too_short_87': 6,\n",
       "  'too_short_175': 1,\n",
       "  'too_short_36': 1,\n",
       "  'too_short_86': 2,\n",
       "  'too_short_71': 3,\n",
       "  'too_short_56': 1,\n",
       "  'too_short_76': 1,\n",
       "  'too_short_171': 1,\n",
       "  'too_short_67': 2,\n",
       "  'too_short_96': 3,\n",
       "  'too_short_109': 2,\n",
       "  'too_short_23': 3,\n",
       "  'too_short_158': 1,\n",
       "  'too_short_57': 1,\n",
       "  'too_short_183': 1,\n",
       "  'too_short_159': 1,\n",
       "  'too_short_164': 1,\n",
       "  'too_short_127': 2,\n",
       "  'too_short_168': 1,\n",
       "  'too_short_70': 2,\n",
       "  'empty_extract': 1,\n",
       "  'too_short_30': 3,\n",
       "  'too_short_131': 1,\n",
       "  'too_short_94': 2,\n",
       "  'too_short_53': 2,\n",
       "  'too_short_142': 2,\n",
       "  'too_short_46': 3,\n",
       "  'too_short_37': 3,\n",
       "  'too_short_81': 3,\n",
       "  'too_short_145': 3,\n",
       "  'too_short_178': 4,\n",
       "  'too_short_54': 1,\n",
       "  'too_short_182': 1,\n",
       "  'too_short_163': 2,\n",
       "  'too_short_102': 2,\n",
       "  'too_short_62': 3,\n",
       "  'too_short_58': 2,\n",
       "  'too_short_66': 2,\n",
       "  'too_short_106': 2,\n",
       "  'too_short_75': 3,\n",
       "  'too_short_38': 3,\n",
       "  'too_short_45': 5,\n",
       "  'too_short_79': 2,\n",
       "  'too_short_147': 1,\n",
       "  'too_short_117': 3,\n",
       "  'too_short_136': 2,\n",
       "  'too_short_41': 1,\n",
       "  'too_short_39': 1,\n",
       "  'too_short_190': 1,\n",
       "  'too_short_140': 1,\n",
       "  'too_short_65': 2,\n",
       "  'too_short_40': 5,\n",
       "  'too_short_157': 4,\n",
       "  'too_short_141': 2,\n",
       "  'too_short_83': 3,\n",
       "  'too_short_44': 1,\n",
       "  'too_short_26': 3,\n",
       "  'too_short_97': 1,\n",
       "  'too_short_55': 2,\n",
       "  'too_short_161': 2,\n",
       "  'too_short_185': 1,\n",
       "  'too_short_196': 1,\n",
       "  'too_short_92': 2,\n",
       "  'too_short_107': 2,\n",
       "  'too_short_27': 4,\n",
       "  'too_short_165': 1,\n",
       "  'too_short_119': 1,\n",
       "  'too_short_184': 1,\n",
       "  'too_short_198': 2,\n",
       "  'too_short_32': 2,\n",
       "  'too_short_17': 1,\n",
       "  'too_short_101': 1,\n",
       "  'too_short_197': 2,\n",
       "  'too_short_144': 1,\n",
       "  'too_short_129': 1,\n",
       "  'too_short_68': 4,\n",
       "  'too_short_193': 1,\n",
       "  'too_short_52': 1,\n",
       "  'too_short_148': 1,\n",
       "  'too_short_90': 2,\n",
       "  'too_short_120': 3,\n",
       "  'too_short_99': 2,\n",
       "  'too_short_154': 2,\n",
       "  'too_short_111': 1,\n",
       "  'too_short_78': 2,\n",
       "  'too_short_60': 3,\n",
       "  'too_short_95': 1,\n",
       "  'too_short_15': 1,\n",
       "  'too_short_110': 1,\n",
       "  'too_short_34': 3,\n",
       "  'too_short_28': 2,\n",
       "  'too_short_91': 1,\n",
       "  'too_short_89': 4,\n",
       "  'too_short_88': 1,\n",
       "  'too_short_125': 1,\n",
       "  'too_short_174': 2,\n",
       "  'too_short_20': 3,\n",
       "  'too_short_104': 1,\n",
       "  'too_short_59': 2,\n",
       "  'too_short_134': 1,\n",
       "  'too_short_151': 1,\n",
       "  'too_short_114': 1,\n",
       "  'too_short_181': 1,\n",
       "  'too_short_122': 2,\n",
       "  'too_short_48': 2,\n",
       "  'too_short_25': 3,\n",
       "  'too_short_186': 2,\n",
       "  'too_short_162': 1,\n",
       "  'too_short_13': 1,\n",
       "  'too_short_47': 1,\n",
       "  'too_short_187': 1,\n",
       "  'too_short_100': 1,\n",
       "  'too_short_115': 2,\n",
       "  'too_short_179': 1,\n",
       "  'too_short_113': 1,\n",
       "  'too_short_128': 1,\n",
       "  'too_short_170': 2,\n",
       "  'too_short_85': 1,\n",
       "  'too_short_130': 1,\n",
       "  'too_short_188': 1,\n",
       "  'too_short_77': 1,\n",
       "  'too_short_167': 1,\n",
       "  'too_short_155': 1,\n",
       "  'too_short_69': 1,\n",
       "  'too_short_61': 1,\n",
       "  'too_short_98': 1},\n",
       " 'errors': {},\n",
       " 'out': 'data/random_urls.json'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Set (300 URLs), minimum 200 words per page. These should change every time the system is rebuilt/indexed.\n",
    "from src.build.build_random_urls import build_random_urls\n",
    "build_random_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2faf6f1-1666-4974-ba9b-fc0bd9a7499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "942fe29c-1038-45fd-9b8e-9e32adc9e8cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25/500 URLs | pages_ok=25 | chunks=397\n",
      "Processed 50/500 URLs | pages_ok=50 | chunks=773\n",
      "Processed 75/500 URLs | pages_ok=75 | chunks=1181\n",
      "Processed 100/500 URLs | pages_ok=100 | chunks=1596\n",
      "Processed 125/500 URLs | pages_ok=125 | chunks=1911\n",
      "Processed 150/500 URLs | pages_ok=150 | chunks=2101\n",
      "Processed 175/500 URLs | pages_ok=175 | chunks=2439\n",
      "Processed 200/500 URLs | pages_ok=200 | chunks=2649\n",
      "Processed 225/500 URLs | pages_ok=225 | chunks=2737\n",
      "Processed 250/500 URLs | pages_ok=250 | chunks=2860\n",
      "Processed 275/500 URLs | pages_ok=275 | chunks=3006\n",
      "Processed 300/500 URLs | pages_ok=300 | chunks=3128\n",
      "Processed 325/500 URLs | pages_ok=325 | chunks=3215\n",
      "Processed 350/500 URLs | pages_ok=350 | chunks=3354\n",
      "Processed 375/500 URLs | pages_ok=375 | chunks=3456\n",
      "Processed 400/500 URLs | pages_ok=400 | chunks=3575\n",
      "Processed 425/500 URLs | pages_ok=425 | chunks=3700\n",
      "Processed 450/500 URLs | pages_ok=450 | chunks=3792\n",
      "Processed 475/500 URLs | pages_ok=475 | chunks=3904\n",
      "Processed 500/500 URLs | pages_ok=500 | chunks=4060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'urls_seen': 500,\n",
       " 'pages_ok': 500,\n",
       " 'total_chunks': 4060,\n",
       " 'stats': {'pages_ok': 500},\n",
       " 'out': 'data/corpus_chunks.jsonl'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Corpus: 200 fixed + 300 random = 500 URLs. Extract, clean, and chunk the text (200-400 tokens with 50-token overlap). \n",
    "from src.build.build_corpus import build_corpus\n",
    "build_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ce374f5-b804-420c-a45c-2e89283ee896",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow<2.21,>=2.20 (from tf-keras)\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.33.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.73.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.6.15)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/331.9 MB 4.8 MB/s eta 0:01:09\n",
      "   ---------------------------------------- 1.8/331.9 MB 5.0 MB/s eta 0:01:06\n",
      "   ---------------------------------------- 3.1/331.9 MB 5.3 MB/s eta 0:01:03\n",
      "    --------------------------------------- 4.2/331.9 MB 5.1 MB/s eta 0:01:04\n",
      "    --------------------------------------- 5.2/331.9 MB 5.1 MB/s eta 0:01:05\n",
      "    --------------------------------------- 6.3/331.9 MB 5.1 MB/s eta 0:01:05\n",
      "    --------------------------------------- 7.3/331.9 MB 5.1 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.7/331.9 MB 5.1 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 9.7/331.9 MB 5.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 10.7/331.9 MB 5.2 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 11.8/331.9 MB 5.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 12.8/331.9 MB 5.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 13.9/331.9 MB 5.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 14.9/331.9 MB 5.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 16.0/331.9 MB 5.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 17.0/331.9 MB 5.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 18.1/331.9 MB 5.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 19.1/331.9 MB 5.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 20.2/331.9 MB 5.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 21.0/331.9 MB 5.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 22.0/331.9 MB 5.0 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 23.1/331.9 MB 5.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 23.9/331.9 MB 5.0 MB/s eta 0:01:02\n",
      "   --- ------------------------------------ 24.9/331.9 MB 5.0 MB/s eta 0:01:02\n",
      "   --- ------------------------------------ 26.2/331.9 MB 5.0 MB/s eta 0:01:02\n",
      "   --- ------------------------------------ 27.3/331.9 MB 5.0 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 28.6/331.9 MB 5.0 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 29.6/331.9 MB 5.1 MB/s eta 0:01:00\n",
      "   --- ------------------------------------ 30.9/331.9 MB 5.1 MB/s eta 0:01:00\n",
      "   --- ------------------------------------ 32.0/331.9 MB 5.1 MB/s eta 0:00:59\n",
      "   --- ------------------------------------ 33.0/331.9 MB 5.1 MB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 34.3/331.9 MB 5.1 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 35.7/331.9 MB 5.2 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 36.7/331.9 MB 5.2 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 38.0/331.9 MB 5.2 MB/s eta 0:00:57\n",
      "   ---- ----------------------------------- 39.3/331.9 MB 5.2 MB/s eta 0:00:57\n",
      "   ---- ----------------------------------- 40.4/331.9 MB 5.2 MB/s eta 0:00:56\n",
      "   ----- ---------------------------------- 41.7/331.9 MB 5.3 MB/s eta 0:00:56\n",
      "   ----- ---------------------------------- 43.0/331.9 MB 5.3 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 44.3/331.9 MB 5.3 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 45.4/331.9 MB 5.3 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 46.7/331.9 MB 5.3 MB/s eta 0:00:54\n",
      "   ----- ---------------------------------- 47.4/331.9 MB 5.3 MB/s eta 0:00:54\n",
      "   ----- ---------------------------------- 49.0/331.9 MB 5.3 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 50.3/331.9 MB 5.3 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 51.4/331.9 MB 5.3 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 52.7/331.9 MB 5.4 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 53.7/331.9 MB 5.3 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 55.1/331.9 MB 5.4 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 56.1/331.9 MB 5.4 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 57.1/331.9 MB 5.4 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 58.5/331.9 MB 5.4 MB/s eta 0:00:51\n",
      "   ------- -------------------------------- 59.8/331.9 MB 5.4 MB/s eta 0:00:51\n",
      "   ------- -------------------------------- 61.1/331.9 MB 5.4 MB/s eta 0:00:51\n",
      "   ------- -------------------------------- 62.4/331.9 MB 5.4 MB/s eta 0:00:50\n",
      "   ------- -------------------------------- 63.4/331.9 MB 5.4 MB/s eta 0:00:50\n",
      "   ------- -------------------------------- 64.7/331.9 MB 5.4 MB/s eta 0:00:50\n",
      "   ------- -------------------------------- 66.1/331.9 MB 5.4 MB/s eta 0:00:49\n",
      "   -------- ------------------------------- 67.1/331.9 MB 5.5 MB/s eta 0:00:49\n",
      "   -------- ------------------------------- 68.4/331.9 MB 5.5 MB/s eta 0:00:49\n",
      "   -------- ------------------------------- 69.7/331.9 MB 5.5 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 71.0/331.9 MB 5.5 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 72.4/331.9 MB 5.5 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 73.4/331.9 MB 5.5 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 74.4/331.9 MB 5.5 MB/s eta 0:00:47\n",
      "   --------- ------------------------------ 75.8/331.9 MB 5.5 MB/s eta 0:00:47\n",
      "   --------- ------------------------------ 77.1/331.9 MB 5.5 MB/s eta 0:00:47\n",
      "   --------- ------------------------------ 78.4/331.9 MB 5.5 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 79.4/331.9 MB 5.5 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 80.7/331.9 MB 5.5 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 81.8/331.9 MB 5.5 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 83.1/331.9 MB 5.5 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 84.4/331.9 MB 5.5 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 85.5/331.9 MB 5.5 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 86.8/331.9 MB 5.5 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 88.1/331.9 MB 5.6 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 89.4/331.9 MB 5.6 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 90.7/331.9 MB 5.6 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 92.0/331.9 MB 5.6 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 93.3/331.9 MB 5.6 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 94.4/331.9 MB 5.6 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 95.7/331.9 MB 5.6 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 97.0/331.9 MB 5.6 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 98.3/331.9 MB 5.6 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 99.4/331.9 MB 5.6 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 100.9/331.9 MB 5.6 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 102.2/331.9 MB 5.6 MB/s eta 0:00:41\n",
      "   ------------ --------------------------- 103.5/331.9 MB 5.6 MB/s eta 0:00:41\n",
      "   ------------ --------------------------- 104.9/331.9 MB 5.6 MB/s eta 0:00:41\n",
      "   ------------ --------------------------- 106.4/331.9 MB 5.7 MB/s eta 0:00:40\n",
      "   ------------ --------------------------- 107.5/331.9 MB 5.7 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 108.5/331.9 MB 5.7 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 110.1/331.9 MB 5.7 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 111.7/331.9 MB 5.7 MB/s eta 0:00:39\n",
      "   ------------- -------------------------- 113.0/331.9 MB 5.7 MB/s eta 0:00:39\n",
      "   ------------- -------------------------- 114.3/331.9 MB 5.7 MB/s eta 0:00:39\n",
      "   ------------- -------------------------- 115.6/331.9 MB 5.7 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 117.2/331.9 MB 5.7 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 118.5/331.9 MB 5.7 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 120.1/331.9 MB 5.7 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 121.6/331.9 MB 5.8 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 122.9/331.9 MB 5.8 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 124.5/331.9 MB 5.8 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 126.1/331.9 MB 5.8 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 127.7/331.9 MB 5.8 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 129.0/331.9 MB 5.8 MB/s eta 0:00:35\n",
      "   --------------- ------------------------ 130.5/331.9 MB 5.8 MB/s eta 0:00:35\n",
      "   --------------- ------------------------ 131.9/331.9 MB 5.8 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 133.4/331.9 MB 5.8 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 135.0/331.9 MB 5.9 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 136.3/331.9 MB 5.9 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 137.6/331.9 MB 5.9 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 139.2/331.9 MB 5.9 MB/s eta 0:00:33\n",
      "   ---------------- ----------------------- 140.5/331.9 MB 5.9 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 141.8/331.9 MB 5.9 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 143.4/331.9 MB 5.9 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 144.7/331.9 MB 5.9 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 145.8/331.9 MB 5.9 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 147.3/331.9 MB 5.9 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 148.6/331.9 MB 5.9 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 149.9/331.9 MB 5.9 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 151.3/331.9 MB 5.9 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 152.6/331.9 MB 5.9 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 153.9/331.9 MB 5.9 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 155.2/331.9 MB 5.9 MB/s eta 0:00:30\n",
      "   ------------------ --------------------- 156.5/331.9 MB 5.9 MB/s eta 0:00:30\n",
      "   ------------------ --------------------- 157.5/331.9 MB 5.9 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 159.1/331.9 MB 5.9 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 160.4/331.9 MB 5.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 161.2/331.9 MB 5.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 162.5/331.9 MB 5.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 163.6/331.9 MB 5.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 164.9/331.9 MB 5.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 165.9/331.9 MB 5.9 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 167.2/331.9 MB 5.9 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 168.3/331.9 MB 5.9 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 169.6/331.9 MB 5.9 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 170.9/331.9 MB 5.9 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 172.2/331.9 MB 5.9 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 173.3/331.9 MB 5.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 174.9/331.9 MB 5.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 175.9/331.9 MB 5.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 177.2/331.9 MB 5.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 178.3/331.9 MB 5.9 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 179.8/331.9 MB 5.9 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 180.9/331.9 MB 5.9 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 182.5/331.9 MB 6.0 MB/s eta 0:00:26\n",
      "   ---------------------- ----------------- 183.5/331.9 MB 6.0 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 184.8/331.9 MB 6.0 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 186.1/331.9 MB 6.0 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 187.7/331.9 MB 6.0 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 189.0/331.9 MB 6.0 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 190.1/331.9 MB 6.0 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 191.6/331.9 MB 6.0 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 192.7/331.9 MB 6.0 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 194.0/331.9 MB 6.0 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 195.8/331.9 MB 6.0 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 197.1/331.9 MB 6.1 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 198.7/331.9 MB 6.1 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 200.0/331.9 MB 6.1 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 201.6/331.9 MB 6.1 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 202.9/331.9 MB 6.1 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 204.5/331.9 MB 6.1 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 206.0/331.9 MB 6.1 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 207.4/331.9 MB 6.2 MB/s eta 0:00:21\n",
      "   ------------------------- -------------- 208.7/331.9 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 210.0/331.9 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 211.3/331.9 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 212.9/331.9 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 214.2/331.9 MB 6.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 215.7/331.9 MB 6.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 217.3/331.9 MB 6.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 218.9/331.9 MB 6.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 220.5/331.9 MB 6.3 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 222.0/331.9 MB 6.3 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 223.6/331.9 MB 6.3 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 225.2/331.9 MB 6.3 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 226.5/331.9 MB 6.3 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 228.1/331.9 MB 6.3 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 229.6/331.9 MB 6.3 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 230.9/331.9 MB 6.3 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 232.8/331.9 MB 6.3 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 234.4/331.9 MB 6.3 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 235.7/331.9 MB 6.4 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 237.2/331.9 MB 6.4 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 238.8/331.9 MB 6.4 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 239.9/331.9 MB 6.4 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 241.2/331.9 MB 6.4 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 242.5/331.9 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 244.1/331.9 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 245.4/331.9 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 246.9/331.9 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 248.5/331.9 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 250.1/331.9 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 251.7/331.9 MB 6.5 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 253.2/331.9 MB 6.5 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 254.8/331.9 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 256.1/331.9 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 257.4/331.9 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 259.0/331.9 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 260.0/331.9 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 261.4/331.9 MB 6.5 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 262.7/331.9 MB 6.5 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 264.2/331.9 MB 6.5 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 265.6/331.9 MB 6.5 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 266.9/331.9 MB 6.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 268.2/331.9 MB 6.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 269.7/331.9 MB 6.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 271.1/331.9 MB 6.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 272.6/331.9 MB 6.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 273.2/331.9 MB 6.5 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 273.9/331.9 MB 6.5 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 275.5/331.9 MB 6.5 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 277.1/331.9 MB 6.5 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 278.9/331.9 MB 6.5 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 280.2/331.9 MB 6.5 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 281.5/331.9 MB 6.5 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 283.4/331.9 MB 6.6 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 284.7/331.9 MB 6.6 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 286.3/331.9 MB 6.6 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 287.8/331.9 MB 6.6 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 289.4/331.9 MB 6.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 290.7/331.9 MB 6.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 292.3/331.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 293.6/331.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 294.9/331.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 296.2/331.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 297.5/331.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 298.8/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 299.9/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 301.2/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 302.3/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 303.6/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 304.6/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 305.7/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 307.0/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 308.0/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 309.3/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 310.6/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 312.0/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 313.3/331.9 MB 6.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 314.3/331.9 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 315.6/331.9 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 316.9/331.9 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 318.0/331.9 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 319.3/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 320.6/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 321.7/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 323.0/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  324.3/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  325.3/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  326.6/331.9 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  327.9/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  329.0/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.3/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.6/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.9/331.9 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.5 MB 7.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 5.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard, tensorflow, tf-keras\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.19.0\n",
      "    Uninstalling tensorboard-2.19.0:\n",
      "      Successfully uninstalled tensorboard-2.19.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.19.0\n",
      "    Uninstalling tensorflow-2.19.0:\n",
      "      Successfully uninstalled tensorflow-2.19.0\n",
      "Successfully installed tensorboard-2.20.0 tensorflow-2.20.0 tf-keras-2.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\stanh\\anaconda3\\Lib\\site-packages\\~ensorflow'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "704898ac-d9e8-4021-8b7f-46345df5a622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collection': 'wiki_chunks_dense',\n",
       " 'persist_dir': 'indexes/chroma',\n",
       " 'num_chunks_indexed': 4060,\n",
       " 'embedding_model': 'all-MiniLM-L6-v2'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store with metadata (URL, title, unique chunk IDs).\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.index.dense_chroma import build_dense_index\n",
    "build_dense_index(corpus_path=\"data/corpus_chunks.jsonl\",\n",
    "                  embedding_model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3067e3e9-e5d0-4c5f-b1eb-3fe29ffd54be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4060\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient(path=\"indexes/chroma\")\n",
    "col = client.get_collection(\"wiki_chunks_dense\")\n",
    "print(col.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e9bc5-7a0b-4d87-ac59-4ba84f3f35dc",
   "metadata": {},
   "source": [
    "<h1> Part 1: Hybrid RAG System (10 Marks) </h1>\n",
    "<h2>1.1 Dense Vector Retrieval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12f04bc-4a10-46fc-ab93-b992ffadce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\stanh\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "1 0.6111284494400024 Mathematics https://en.wikipedia.org/wiki/Mathematics\n",
      "2 0.5163175463676453 Astronomy https://en.wikipedia.org/wiki/Astronomy\n",
      "3 0.4944854974746704 Astronomy https://en.wikipedia.org/wiki/Astronomy\n",
      "4 0.4509149193763733 Mathematics https://en.wikipedia.org/wiki/Mathematics\n",
      "5 0.44798386096954346 Astronomy https://en.wikipedia.org/wiki/Astronomy\n"
     ]
    }
   ],
   "source": [
    "from src.index.dense_chroma import dense_retrieve\n",
    "\n",
    "results = dense_retrieve(\"Who developed the theory of relativity?\", top_k=5)\n",
    "for r in results:\n",
    "    print(r[\"dense_rank\"], r[\"dense_score\"], r[\"title\"], r[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc235c8-febd-47e3-99cd-fcc1381a3371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\stanh\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from rank-bm25) (1.26.4)\n",
      "Requirement already satisfied: click in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install rank-bm25 nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b55b20-d48b-46e1-9bcd-9263319c6957",
   "metadata": {},
   "source": [
    "<h2>1.2 Sparse Keyword Retrieval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b1bcbb-de00-46ef-81ae-9d1499dd3fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bm25_docs_indexed': 4060,\n",
       " 'bm25_path': 'indexes\\\\bm25.pkl',\n",
       " 'meta_path': 'indexes\\\\bm25_meta.pkl'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.index.sparse_bm25 import build_bm25_index\n",
    "build_bm25_index(\"data/corpus_chunks.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784453cd-61e4-4b7b-a6bf-bd094de1cd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 25.20968642794734 Mathematics https://en.wikipedia.org/wiki/Mathematics\n",
      "2 19.08023813509117 Shockwave cosmology https://en.wikipedia.org/wiki/Shockwave_cosmology\n",
      "3 17.184648792448428 Outline of astronomy https://en.wikipedia.org/wiki/Outline_of_astronomy\n",
      "4 17.149402801341083 Outline of astronomy https://en.wikipedia.org/wiki/Outline_of_astronomy\n",
      "5 16.775726205159664 Mathematics https://en.wikipedia.org/wiki/Mathematics\n"
     ]
    }
   ],
   "source": [
    "from src.index.sparse_bm25 import sparse_retrieve\n",
    "\n",
    "res = sparse_retrieve(\"Who developed the theory of relativity?\", top_k=5)\n",
    "for r in res:\n",
    "    print(r[\"bm25_rank\"], r[\"bm25_score\"], r[\"title\"], r[\"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca91f445-cfc6-45e9-9c37-1d36f8e9f62f",
   "metadata": {},
   "source": [
    "<h2>1.3 Reciprocal Rank Fusion (RRF)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab610087-d19e-487c-97ae-700e98ffb2b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query =\"Wayland Balloon Fest ?\"\n",
    "\n",
    "dense_results = dense_retrieve(query, top_k=30)\n",
    "sparse_results = sparse_retrieve(query, top_k=30)\n",
    "\n",
    "from src.rag.rrf import rrf_fusion\n",
    "\n",
    "final_context_chunks = rrf_fusion(\n",
    "    dense_results,\n",
    "    sparse_results,\n",
    "    k=60,\n",
    "    top_n=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e8443b9-bf4c-4696-b96b-80a44c369645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Context 1\n",
      "URL: https://en.wikipedia.org/wiki/The_Air_Balloon,_Birdlip\n",
      "RRF score: 0.032522\n",
      "--------------------------------------------------------------------------------\n",
      "The Air Balloon is a road junction and former pub in Birdlip, Gloucestershire, England. The junction is on the A417 at a significant congestion point. The pub was open from the late 18th century to 2022, when it closed as part of road improvements, and was subsequently demolished. == Location == The pub stood next to a roundabout junction on the A417, a major road between Swindon and Gloucester via Cirencester. The A436 meets the A417 at this point; the two roads together form a de facto bypass of Cheltenham between Oxford and Gloucester. == History == The pub opened in 1784 and was probably named after one of the first British balloon flights: the launching of a small hydrogen balloon by Edward Jenner on 2 September of that year, which flew from Berkeley Castle to Kingscote and then on to a field near Birdlip. This was the year after the pioneering flights of the Montgolfier brothers' hot air balloon and Jacques Charles's hydrogen balloon in Paris. It was known as the Balloon by 1796 and renamed the Air Balloon in 1802. By 1856, the landlord was brewing beer on-site. The premises were part of the Cowley Manor estate until some time early in the 20th century. The pub was bought by Greene\n",
      "\n",
      "📄 Context 2\n",
      "URL: https://en.wikipedia.org/wiki/Calkins_Field\n",
      "RRF score: 0.032522\n",
      "--------------------------------------------------------------------------------\n",
      "Calkins Field (FAA LID: 41C) is a privately owned, public use airport located 1 mile north of Wayland, Michigan. The airport sits on 105 acres at an elevation of 740 feet. The airport is named for the Calkins Family, which has lived in the Wayland area for generations. The airport is located on their property. == Facilities and aircraft == The airport has two runways, both made of turf. Runway 1/19 measures 2200 x 75 ft (671 x 23 m), and runway 9/27 measures 1800 x 100 ft (549 x 30 m). For the 12-month period ending December 31, 2015, the airport had 1508 aircraft operations, an average of 29 per week. It was all general aviation. For the same time period, 10 aircraft are based at the airport: 9 single-engine airplanes and 1 ultralight. The airport does not have a fixed-base operator. No fuel is available at the airport. == Wayland Balloon Fest == The airport holds an annual hot air balloon show called the Wayland Ballon Fest. The event features hot air balloon flights, food, live music, and meet-and-greets with the balloon pilots. The event also features a 5K run. The first event was held in 2021, and it continued for a second year in 2022., live music, and meet-and-greets with the balloon pilots. The event also features a 5K run. The first event was held in 2021, and it continued for a second year in 2022. The event raises money for suicide prevention efforts. Organizers say they lost family members to suicide in the past and hope to help others receive assistance. ==\n",
      "\n",
      "📄 Context 3\n",
      "URL: https://en.wikipedia.org/wiki/The_Air_Balloon,_Birdlip\n",
      "RRF score: 0.02967\n",
      "--------------------------------------------------------------------------------\n",
      "the Air Balloon in 1802. By 1856, the landlord was brewing beer on-site. The premises were part of the Cowley Manor estate until some time early in the 20th century. The pub was bought by Greene King in 2004. In 2020 the menu included burgers, steaks, vegetarian food, \"pub classics\" and a lunchtime carvery. == Closure == The pub was under threat of demolition as it sat alongside a short section of single-carriageway road which is otherwise a high-quality route between the M4 and M5 motorways. Although the junction has been said to be a notorious accident blackspot, from 1999 to 2014 there were an estimated 340 casualties along the whole section of road, which National Highways said was below average for the type of road. In March 2019, Highways England proposed improvements that would include demolition of the pub, stating that the local geography and steep hills made it otherwise impossible to build a high-quality road meeting modern safety standards. The road could not be routed elsewhere as it would cut through Barrow Wake, which is a Site of Special Scientific Interest. Highways England stated that it would consult landowners and assess the social impact of the pub's demolition in a further design stage. As of June 2021, the pub was open, but was expected to be demolished. The\n",
      "\n",
      "📄 Context 4\n",
      "URL: https://en.wikipedia.org/wiki/Yonder_Mountain_String_Band\n",
      "RRF score: 0.029206\n",
      "--------------------------------------------------------------------------------\n",
      "was to open for a band at the Fox Theatre in Boulder. The band developed both a bluegrass and jam band fan base, and can often be found on tour. Their debut album Elevation was released on Frog Pad Records, an independent record label run by the band, in the fall of 1999. From 1999 to 2001 they performed as one of the many attractions at NedFest, a music festival held in the band's hometown. By 2000, the group was also playing larger venues, such as The Fillmore in San Francisco, California. In 2005, their recording of \"Think for Yourself\" was included on the album This Bird Has Flown – A 40th Anniversary Tribute to the Beatles' Rubber Soul. In 2008, the band performed at the 2008 Democratic National Convention in Denver. In 2010, Yonder Mountain decided to host a music festival at Mulberry Mountain in Ozark, Arkansas called Yonder Mountain's Harvest Festival. This is the same site where the larger Wakarusa festival is held and where the previous Mulberry Mountain Harvest Fest was held. In 2011, the festival's headliners included Bela Fleck and the Flecktones, the Simcha Aknin Band, Railroad Earth and the Emmitt-Nershi Band. In April 2014, Austin left the band due to \"creative differences and conflicting career goals\". After touring with the band since Austin'\n",
      "\n",
      "📄 Context 5\n",
      "URL: https://en.wikipedia.org/wiki/The_Air_Balloon,_Birdlip\n",
      "RRF score: 0.028439\n",
      "--------------------------------------------------------------------------------\n",
      "Highways England stated that it would consult landowners and assess the social impact of the pub's demolition in a further design stage. As of June 2021, the pub was open, but was expected to be demolished. The landlord subsequently announced in December 2022 that the pub would close on New Year's Eve, and then it would be demolished. Actor John Challis' widow said the couple used to visit the pub regularly, and she was sad to see it close. A spokesperson for Highways England expressed surprise at the pub's closure, saying it could have stayed open longer. There were additional concerns that a now-closed prominent landmark could become a magnet for vandalism. The premises were demolished in December 2023 as part of the construction work. On 21 July 2024, four people were killed after a car crash on the A436 between the Air Balloon and Seven Springs. ==\n",
      "\n",
      "📄 Context 6\n",
      "URL: https://en.wikipedia.org/wiki/Ephemeral_architecture\n",
      "RRF score: 0.026688\n",
      "--------------------------------------------------------------------------------\n",
      "=== Plug in city. Archigram, 1962–1966 === A megastructure that had no buildings, just a large frame into which housing or service capsules could be fitted in the form of cells or standardized components. Each element had a durability; the base tubular structure 40 years, in the capsules it varies according to its program, from 6 months for a commercial space, to 5–8 years for bedrooms and living rooms. At the top an inflatable balloon is activated in bad weather. === Living Pod. David Greene, Archigram, 1966 === It is a habitat-capsule that can be inserted inside an urban structure called plug-in, or it can be transported and perched on any natural landscape. A hybrid architecture, hermetic, small, comfortable and technological, constituted by the space itself and by the machines connected to it: \"The house is an apparatus to be transported with itself, the city is a machine to which you connect.\" Although comparable to a capsule, the Living Pod does not have autonomy, that is why in 1969 he proposed the Logplug-Rockplug. Real simulations of logs and rocks that serve to hide service points for semi-autonomous living containers. They go unnoticed, perfectly adapted to the landscape and bring to any environment a high degree of technological support without detrac\n",
      "\n",
      "📄 Context 7\n",
      "URL: https://en.wikipedia.org/wiki/Macedonia_in_the_Eurovision_Song_Contest_2002\n",
      "RRF score: 0.015873\n",
      "--------------------------------------------------------------------------------\n",
      "point was fifteenth, achieved in 2000 with the song \"100% te ljubam\" performed by XXL. As part of its duties as participating broadcaster, MRT organises the selection of its entry in the Eurovision Song Contest and broadcasts the event in the country. The broadcaster had previously selected both of its entries for the contest by using the national final Skopje Fest. For 2002, the broadcaster again opted to select its entry through Skopje Fest. == Before Eurovision == === Skopje Fest 2002 === MRT used the 2002 edition of the Skopje Fest song contest to select its entry for the Eurovision Song Contest 2002. A submission period was opened for interested composers to submit their songs and MRT received 121 submissions at the closing of the deadline. Eighteen competing artists and songs were selected in late September 2001 by a nine-member committee consisting of Nikola Dimuevski, Aleksandar Dambazov, Ilija Pejovski, ivoin Glisi, Traje Organdiev, Bodan Arsovski, Biljana Nikolovska, Dragan Kosti and Zoran Mirevski. Bilen Eminov, Maja Odaklievska (in a due\n",
      "\n",
      "📄 Context 8\n",
      "URL: https://en.wikipedia.org/wiki/Barrfields_Pavilion\n",
      "RRF score: 0.015625\n",
      "--------------------------------------------------------------------------------\n",
      "Refurbishment == The theatre was refurbished in 1995, reconstructed alongside a new centre at Barrfields Theatre and Pool called Vikingar. Seating was reduced to 500, and new spacious foyers were created along with dressing room block, Winter Garden Cafe Bar, and new stage facilities. The theatre is now owned by North Ayrshire Council and under the management of North Ayrshire Leisure Entertainments. The Barrfields Theatre has a programme which has a strong tradition of amateur dramatic productions, popular children's entertainments, variety, Scottish plays, ballet and touring productions and more staged throughout the year. == Revival == In March 2012, a new voluntary group, Barrfields User Group, was set up to develop and promote the Barrfields Theatre facility. == Location == The theatre is situated as part of the Vikingar leisure Centre, Barrfields, Greenock Road, Largs. This is part of the municipal policies of Barrfields along with the sports ground and putting green. ==\n",
      "\n",
      "📄 Context 9\n",
      "URL: https://en.wikipedia.org/wiki/Spain_in_the_Eurovision_Song_Contest_2024\n",
      "RRF score: 0.015625\n",
      "--------------------------------------------------------------------------------\n",
      "while the 2023 contest was still ongoing, announcing the organisation of the third edition of Benidorm Fest in order to select its next entry. == Before Eurovision == === Benidorm Fest 2024 === Benidorm Fest 2024 was the third edition of Benidorm Fest, organised by RTVE and Generalitat Valenciana to select the Spanish entry for the Eurovision Song Contest 2024. The event took place at the Palau Municipal d'Esports l'Illa de Benidorm in Benidorm, Valencian Community. Sixteen artists and songs competed over three shows: two semi-finals on 30 January and 1 February 2024, and the final on 3 February 2024, with a total of eight entries ultimately qualifying to the final. The voting consisted of televote (25%), a demoscopic panel of judges made up of a sample of the Spanish population selected by statistical and demoscopic criteria (25%), and a national and international jury vote (50%). ==== Semi-finals ==== The first semi-final took place on 31 January 2023. \"Zorra\" performed by Nebulossa, \"Sé quién soy\" performed by Angy Fernández, \"Here to Stay\"\n",
      "\n",
      "📄 Context 10\n",
      "URL: https://en.wikipedia.org/wiki/Spain_in_the_Eurovision_Song_Contest_2024\n",
      "RRF score: 0.015385\n",
      "--------------------------------------------------------------------------------\n",
      "omé, the latter having won in a four-way tie with France, the Netherlands, and the United Kingdom. They have also finished second four times, with \"En un mundo nuevo\" by Karina in 1971, \"Eres t\" by Mocedades in 1973, \"Su canción\" by Betty Missiego in 1979, and \"Vuelve conmigo\" by Anabel Conde in 1995. In 2022, RTVE placed third with the song \"SloMo\" performed by Chanel, while in 2023, it came 17th with the song \"Eaea\" performed by Blanca Paloma. As part of its duties as participating broadcaster, RTVE organises the selection of its entry in the Eurovision Song Contest and broadcasts the event in the country. The Spanish broadcaster has selected its entry for the Eurovision Song Contest through both national finals and internal selections in the past, with the national final Benidorm Fest being used since 2022. RTVE confirmed its intentions to participate at the 2024 contest on 11 May 2023, while the 2023 contest was still ongoing, announcing the organisation of the third edition of Benidorm Fest in order to select its next entry. == Before Eurovision == === Benidorm Fest 20\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(final_context_chunks, start=1):\n",
    "    print(f\"\\n📄 Context {i}\")\n",
    "    print(\"URL:\", c.get(\"url\"))\n",
    "    print(\"RRF score:\", round(c[\"rrf_score\"], 6))\n",
    "    print(\"-\"*80)\n",
    "    print(c[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0363c-b3a1-4fc6-8d2f-0ba0a912200e",
   "metadata": {},
   "source": [
    "<h2>1.4 Response Generation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3256d11f-15cc-4df5-bc9f-2843f3eae5a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install transformers sentencepiece torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "933ac88e-8cc1-4b84-81fc-4fe6f26ce9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Paths in the directory\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30ebe7c9-1974-47db-8257-dfe6fa80a408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1) The Air Balloon, Birdlip | https://en.wikipedia.org/wiki/The_Air_Balloon,_Birdlip | RRF=0.03252\n",
      "The Air Balloon is a road junction and former pub in Birdlip, Gloucestershire, England. The junction is on the A417 at a significant congestion point. The pub was open from the late 18th century to 2022, when it closed as part of road improvements, a\n",
      "\n",
      "2) Calkins Field | https://en.wikipedia.org/wiki/Calkins_Field | RRF=0.03252\n",
      "Calkins Field (FAA LID: 41C) is a privately owned, public use airport located 1 mile north of Wayland, Michigan. The airport sits on 105 acres at an elevation of 740 feet. The airport is named for the Calkins Family, which has lived in the Wayland ar\n",
      "\n",
      "3) The Air Balloon, Birdlip | https://en.wikipedia.org/wiki/The_Air_Balloon,_Birdlip | RRF=0.02967\n",
      "the Air Balloon in 1802. By 1856, the landlord was brewing beer on-site. The premises were part of the Cowley Manor estate until some time early in the 20th century. The pub was bought by Greene King in 2004. In 2020 the menu included burgers, steaks\n",
      "\n",
      "4) Yonder Mountain String Band | https://en.wikipedia.org/wiki/Yonder_Mountain_String_Band | RRF=0.02921\n",
      "was to open for a band at the Fox Theatre in Boulder. The band developed both a bluegrass and jam band fan base, and can often be found on tour. Their debut album Elevation was released on Frog Pad Records, an independent record label run by the band\n",
      "\n",
      "5) The Air Balloon, Birdlip | https://en.wikipedia.org/wiki/The_Air_Balloon,_Birdlip | RRF=0.02844\n",
      "Highways England stated that it would consult landowners and assess the social impact of the pub's demolition in a further design stage. As of June 2021, the pub was open, but was expected to be demolished. The landlord subsequently announced in Dece\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(final_context_chunks[:5], start=1):\n",
    "    print(f\"\\n{i}) {c.get('title')} | {c.get('url')} | RRF={c['rrf_score']:.5f}\")\n",
    "    print(c[\"text\"][:250].replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7856e770-2151-4821-98d8-f13b45f3e00d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use ONLY the context to answer the question.\n",
      "If the answer is not present in the context, reply exactly: Not available in context.\n",
      "\n",
      "Provide a complete and concise answer ending with a full stop.\n",
      "\n",
      "Context:\n",
      "The Air Balloon is a road junction and former pub in Birdlip, Gloucestershire, England. The junction is on the A417 at a significant congestion point. The pub was open from the late 18th century to 2022, when it closed as part of road improvements, and was subsequently demolished. == Location == The pub stood next to a roundabout junction on the A417, a major road between Swindon and Gloucester via Cirencester. The A436 meets the A417 at this point; the two roads together form a de facto bypass of Cheltenham between Oxford and Gloucester. == History == The pub opened in 1784 and was probably named after one of the first British balloon flights: the launching of a small hydrogen balloon by Ed\n",
      "\n",
      "---\n",
      "\n",
      "Calkins Field (FAA LID: 41C) is a privately owned, public use airport located 1 mile north of Wayland, Michigan. The airport sits on 105 acres at an elevation of 740 feet. The airport is named for the Calkins Family, which has lived in the Wayland area for generations. The airport is located on their property. == Facilities and aircraft == The airport has two runways, both made of turf. Runway 1/19 measures 2200 x 75 ft (671 x 23 m), and runway 9/27 measures 1800 x 100 ft (549 x 30 m). For the 12-month period ending December 31, 2015, the airport had 1508 aircraft operations, an average of 29 per week. It was all general aviation. For the same time period, 10 aircraft are based at the airpor\n",
      "\n",
      "---\n",
      "\n",
      "the Air Balloon in 1802. By 1856, the landlord was brewing beer on-site. The premises were part of the Cowley Manor estate until some time early in the 20th century. The pub was bought by Greene King in 2004. In 2020 the menu included burgers, steaks, vegetarian food, \"pub classics\" and a lunchtime carvery. == Closure == The pub was under threat of demolition as it sat alongside a short section of single-carriageway road which is otherwise a high-quality route between the M4 and M5 motorways. Although the junction has been said to be a notorious accident blackspot, from 1999 to 2014 there were an estimated 340 casualties along the whole section of road, which National Highways said was below\n",
      "\n",
      "---\n",
      "\n",
      "was to open for a band at the Fox Theatre in Boulder. The band developed both a bluegrass and jam band fan base, and can often be found on tour. Their debut album Elevation was released on Frog Pad Records, an independent record label run by the band, in the fall of 1999. From 1999 to 2001 they performed as one of the many attractions at NedFest, a music festival held in the band's hometown. By 2000, the group was also playing larger venues, such as The Fillmore in San Francisco, California. In 2005, their recording of \"Think for Yourself\" was included on the album This Bird Has Flown – A 40th Anniversary Tribute to the Beatles' Rubber Soul. In 2008, the band performed at the 2008 Democratic\n",
      "\n",
      "---\n",
      "\n",
      "Highways England stated that it would consult landowners and assess the social impact of the pub's demolition in a further design stage. As of June 2021, the pub was open, but was expected to be demolished. The landlord subsequently announced in December 2022 that the pub would close on New Year's Eve, and then it would be demolished. Actor John Challis' widow said the couple used to visit the pub regularly, and she was sad to see it close. A spokesperson for Highways England expressed surprise at the pub's closure, saying it could have stayed open longer. There were additional concerns that a now-closed prominent landmark could become a magnet for vandalism. The premises were demolished in \n",
      "\n",
      "---\n",
      "\n",
      "=== Plug in city. Archigram, 1962–1966 === A megastructure that had no buildings, just a large frame into which housing or service capsules could be fitted in the form of cells or standardized components. Each element had a durability; the base structure contained only about 50% of its weight - so if you're looking for something more modern than your old home building look elsewhere! If we don't know what type of material will fit inside our house please let us KNOW!!\n"
     ]
    }
   ],
   "source": [
    "# distilgpt2\n",
    "\n",
    "# from src.rag.generate import generate_answer_distilgpt2\n",
    "# contexts = [c[\"text\"] for c in final_context_chunks]   # top-N from RRF\n",
    "# answer = generate_answer_distilgpt2(query, contexts)\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2882cdd3-4249-4364-bde8-7887d34d47b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " Wayland Balloon Fest is not a public use airport located 1 mile north of Wayland, Michigan. The airport sits on 105 acres at an elevation of 740 feet. Calkins Field is named for the Calkins Family, which has lived in the Wayland area for generations. In March 2012, a new voluntary group, Barrfields User Group, was set up to develop and promote the Barrfield's Theatre facility. Seating was reduced to 500, and new spacious foyers were created along with dressing room block, Winter Garden Cafe Bar,\n",
      "\n",
      "Debug: {'model': 'google/flan-t5-large', 'prompt_tokens': 2041, 'max_input_tokens': 2536, 'max_new_tokens': 220}\n"
     ]
    }
   ],
   "source": [
    "#Generate answers within context limits.\n",
    "from src.rag.generate_flan_t5 import generate_answer_flan_t5\n",
    "\n",
    "contexts = [c[\"text\"] for c in final_context_chunks]   # top-N from RRF\n",
    "\n",
    "answer, debug = generate_answer_flan_t5(\n",
    "    query,\n",
    "    contexts,\n",
    "    max_input_tokens=2536,\n",
    "    max_new_tokens=220\n",
    ")\n",
    "\n",
    "print(\"Answer:\\n\", answer)\n",
    "print(\"\\nDebug:\", debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d80635d9-14d8-440b-9618-5216fb86db80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word football often defaults to the most popular variant, and therefore it refers to association football in regions where that specific variant dominates. This creates conflict in regions that play other versions of football. Within the English-speaking world, association football is now usually called simply \"football\" in Great Britain and most of Ulster in the north of Ireland, whereas people usually call it \"soccer\" in regions and countries where other codes of football are prevalent, such as Australia, Canada, South Africa, most of Ireland (excluding Ulster), and the United States.\n",
      "Time: 65.359\n",
      "Outline of association football 0.03252247488101534\n",
      "Outline of association football 0.0315136476426799\n",
      "Names for association football 0.03036576949620428\n"
     ]
    }
   ],
   "source": [
    "#Pipeline Testing\n",
    "from src.rag.pipeline import run_rag_pipeline\n",
    "\n",
    "out = run_rag_pipeline(\"Association football history\")\n",
    "\n",
    "print(out[\"answer\"])\n",
    "print(\"Time:\", out[\"response_time\"])\n",
    "\n",
    "for c in out[\"contexts\"][:3]:\n",
    "    print(c[\"title\"], c[\"rrf_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6722f-0268-4bf7-a703-10985711b273",
   "metadata": {},
   "source": [
    "<h2> 1.5 User Interface </h2>\n",
    "<h3> Build with Streamlit/Gradio/Flask. Display: user query input, generated answer, top retrieved chunks with sources, dense/sparse/RRF scores, and response time.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eaa800-e134-4a2e-829d-3beb7ce6d832",
   "metadata": {},
   "source": [
    "Please Follow the following steps to run the streamlit\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e158e-e095-4247-b4ef-f1dd1519d071",
   "metadata": {},
   "source": [
    "<h1>Part 2: Automated Evaluation (6 + 4 Marks)</h1>\n",
    "<h2>2.1 Question Generation (Automated)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be796465-9d90-4974-9b73-5e194fe151cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 5, 'out': 'data/questions_100.jsonl'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics.generate_questions import generate_questions\n",
    "\n",
    "res = generate_questions(\n",
    "    corpus_jsonl=\"data/corpus_chunks.jsonl\",\n",
    "    out_jsonl=\"data/questions_100.jsonl\",\n",
    "    seed=7\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dadcc25-72be-47a3-84ab-759dbdcf5d73",
   "metadata": {},
   "source": [
    "<h2>2.2.1 Mandatory Metric (Basic - 2 Marks)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5a99dcf-2aa4-464c-abae-0e42eda12d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.index.dense_chroma import dense_retrieve\n",
    "from src.index.sparse_bm25 import sparse_retrieve\n",
    "from src.rag.rrf import rrf_fusion\n",
    "\n",
    "def retrieval_only(query: str, top_k_dense=50, top_k_sparse=50, top_n_context=50, rrf_k=60):\n",
    "    dense = dense_retrieve(query, top_k=top_k_dense)\n",
    "    sparse = sparse_retrieve(query, top_k=top_k_sparse)\n",
    "    fused = rrf_fusion(dense, sparse, k=rrf_k, top_n=top_n_context)\n",
    "    return fused"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d2e49-534e-49f0-a23b-d1ae65606c6b",
   "metadata": {},
   "source": [
    "<h2>2.2.2 Additional Custom Metrics (4 Marks)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d69c79da-6528-4843-ae7d-d2ea61df60f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.9\n",
      "Precision@5: 0.2\n",
      "Faithfulness: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from src.metrics.run_all_metrics import run_all_metrics\n",
    "run_all_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4b25e-2eda-4b9d-884a-244cff91dc5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h3> URL-level MRR: 0.9</h3>\n",
    "\n",
    "<h3>Metric 1: Precision@5</h3>\n",
    "\n",
    "Why this metric is important\n",
    "\n",
    "Precision@5 measures how many of the top 5 retrieved documents are actually relevant to the query. This metric is important because in a RAG system, the language model only sees a limited number of retrieved documents (usually top-K). If these documents are not relevant, the model may generate incorrect or incomplete answers.\n",
    "\n",
    "Precision@5 helps answer a very practical question:\n",
    "\n",
    "“When my system retrieves 5 documents, how many of them are truly useful?”\n",
    "\n",
    "So, this metric directly evaluates retrieval quality, which is the foundation of any RAG pipeline.\n",
    "\n",
    "\n",
    "\n",
    "<h2>Mathematical formulation</h2>\n",
    "\n",
    "For a given query:\n",
    "\n",
    "Precision@5= (Number of relevant documents in top 5) / 5\n",
    "\t\n",
    "If we evaluate over 𝑁 queries, the final score is the average:\n",
    "\n",
    "Precision@5=  Summation (From 1 - N) of Precision@5(Qi) / N\n",
    "\n",
    "\n",
    "<h2>How it was calculated (implementation logic)</h2>\n",
    "\n",
    "For each query, the retriever returns the top 5 documents. Each document is checked against ground truth to see if it is relevant. The number of relevant documents in the top 5 is counted. This count is divided by 5. The score is averaged across all queries.\n",
    "\n",
    "<h3>Interpretation of my result</h3>\n",
    "\n",
    "<h4>Precision@5 = 0.2, This means that on average, only 1 out of the top 5 retrieved documents is relevant.</h4>\n",
    "\n",
    "The retriever is able to find the correct document sometimes, but most of the retrieved context contains irrelevant or noisy information, this can increase prompt length and reduce answer clarity\n",
    "\n",
    "<h3>Benefit of this metric:</h3>\n",
    "It clearly shows that retrieval needs improvement (better embeddings, chunking, filters, or reranking), even if generation looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82547a68-3c6f-4e0d-882d-a1bc9d9983d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> Metric 2: Faithfulness</h2>\n",
    "<h3> Why this metric is important </h3>\n",
    "\n",
    "Faithfulness measures whether the generated answer is supported by the retrieved documents.\n",
    "Even with RAG, language models can hallucinate or add extra information not present in the context.\n",
    "\n",
    "This metric answers:\n",
    "\n",
    "“Is the model answering only from the provided documents, or inventing facts?”\n",
    "\n",
    "Faithfulness is extremely important for trustworthy AI systems, especially in domains like education, healthcare, or enterprise search.\n",
    "\n",
    "<h3>Mathematical formulation</h3>\n",
    "For a given query:\n",
    "\n",
    "The generated answer is broken into smaller factual claims.\n",
    "\n",
    "Faithfulness = Number of claims supported by context / Total number of claims\n",
    "\n",
    "The final score is averaged over all queries.\n",
    "\n",
    "<h3> How it was calculated (implementation logic) </h3>\n",
    "1. The generated answer is split into individual factual statements.\n",
    "2. Each statement is checked against the retrieved context.\n",
    "3. If the statement is supported by the context, it is marked as faithful.\n",
    "4. The ratio of supported claims to total claims is computed.\n",
    "5. The final score is averaged across queries.\n",
    "\n",
    "\n",
    "<h3> Interpretation of my result </h3>\n",
    "Faithfulness = 0.9667\n",
    "This means that about 96.7% of the generated answer content is directly supported by retrieved documents.\n",
    "\n",
    "<b>What this tells us:</b>\n",
    "The model rarely hallucinates\n",
    "Answers are well grounded in the retrieved context\n",
    "The generation step is working correctly\n",
    "\n",
    "<h3>Benefit of this metric:</h3>\n",
    "It confirms that even when retrieval is noisy, the model is careful not to fabricate information and sticks closely to available evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca5c6a-d8fb-42de-8a06-5862d63df458",
   "metadata": {},
   "source": [
    "<h2>2.3 Innovative Evaluation (4 Marks)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc5428eb-4334-472b-8de1-affb4b5be43a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode- dense\n",
      "K- 7\n",
      "N- 5\n",
      "N- 10\n",
      "K- 10\n",
      "N- 5\n",
      "N- 10\n",
      "Mode- sparse\n",
      "K- 7\n",
      "N- 5\n",
      "N- 10\n",
      "K- 10\n",
      "N- 5\n",
      "N- 10\n",
      "Mode- hybrid\n",
      "K- 7\n",
      "N- 5\n",
      "N- 10\n",
      "K- 10\n",
      "N- 5\n",
      "N- 10\n",
      "     mode  top_k_dense  top_k_sparse  N_context  rrf_k  MRR  Precision@5  \\\n",
      "4  sparse            7             7          5    NaN  1.0          0.2   \n",
      "5  sparse            7             7         10    NaN  1.0          0.2   \n",
      "6  sparse           10            10          5    NaN  1.0          0.2   \n",
      "7  sparse           10            10         10    NaN  1.0          0.2   \n",
      "0   dense            7             7          5    NaN  0.9          0.2   \n",
      "1   dense            7             7         10    NaN  0.9          0.2   \n",
      "2   dense           10            10          5    NaN  0.9          0.2   \n",
      "3   dense           10            10         10    NaN  0.9          0.2   \n",
      "8  hybrid            7             7          5   10.0  0.9          0.2   \n",
      "9  hybrid            7             7          5   60.0  0.9          0.2   \n",
      "\n",
      "   avg_retrieval_time  \n",
      "4            0.211137  \n",
      "5            0.197740  \n",
      "6            0.218415  \n",
      "7            0.229194  \n",
      "0            3.509439  \n",
      "1            3.651056  \n",
      "2            3.608280  \n",
      "3            3.586978  \n",
      "8            3.948047  \n",
      "9            3.680605  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>top_k_dense</th>\n",
       "      <th>top_k_sparse</th>\n",
       "      <th>N_context</th>\n",
       "      <th>rrf_k</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Precision@5</th>\n",
       "      <th>avg_retrieval_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dense</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.509439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dense</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.651056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dense</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.608280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dense</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.586978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sparse</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.211137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sparse</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.197740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sparse</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.218415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sparse</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.229194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.948047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.680605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.701994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.729722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.717109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.678937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.665732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.145728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mode  top_k_dense  top_k_sparse  N_context  rrf_k  MRR  Precision@5  \\\n",
       "0    dense            7             7          5    NaN  0.9          0.2   \n",
       "1    dense            7             7         10    NaN  0.9          0.2   \n",
       "2    dense           10            10          5    NaN  0.9          0.2   \n",
       "3    dense           10            10         10    NaN  0.9          0.2   \n",
       "4   sparse            7             7          5    NaN  1.0          0.2   \n",
       "5   sparse            7             7         10    NaN  1.0          0.2   \n",
       "6   sparse           10            10          5    NaN  1.0          0.2   \n",
       "7   sparse           10            10         10    NaN  1.0          0.2   \n",
       "8   hybrid            7             7          5   10.0  0.9          0.2   \n",
       "9   hybrid            7             7          5   60.0  0.9          0.2   \n",
       "10  hybrid            7             7         10   10.0  0.9          0.2   \n",
       "11  hybrid            7             7         10   60.0  0.9          0.2   \n",
       "12  hybrid           10            10          5   10.0  0.9          0.2   \n",
       "13  hybrid           10            10          5   60.0  0.9          0.2   \n",
       "14  hybrid           10            10         10   10.0  0.9          0.2   \n",
       "15  hybrid           10            10         10   60.0  0.9          0.2   \n",
       "\n",
       "    avg_retrieval_time  \n",
       "0             3.509439  \n",
       "1             3.651056  \n",
       "2             3.608280  \n",
       "3             3.586978  \n",
       "4             0.211137  \n",
       "5             0.197740  \n",
       "6             0.218415  \n",
       "7             0.229194  \n",
       "8             3.948047  \n",
       "9             3.680605  \n",
       "10            3.701994  \n",
       "11            3.729722  \n",
       "12            3.717109  \n",
       "13            3.678937  \n",
       "14            3.665732  \n",
       "15            5.145728  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics.run_ablation import generate_matrix\n",
    "generate_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "574a75e4-5ce9-47ea-82ab-8ba3a3d0d6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done\n",
      "Saved df: data/eval\\df_error_analysis.csv\n",
      "Saved error summary: data/eval\\error_summary.csv\n",
      "Saved plots in: data/eval\n",
      "\n",
      "Error counts:\n",
      "error_type\n",
      "no_error           3\n",
      "context_failure    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from src.metrics.advance_error_analysis import main\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293ba00-ad4b-4c35-96b5-faad0592e640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
