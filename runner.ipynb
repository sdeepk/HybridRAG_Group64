{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ed3d77-8264-44b8-865b-60abbf06e307",
   "metadata": {},
   "source": [
    "## Group No \n",
    " \n",
    "## Group Member Names:\n",
    "|| BITS ID | Name | Contribution |\n",
    "| :------: | :---------------- | :------ | :----: |\n",
    "| 1. | 2024aa05354| ANKIT GUPTA     | 100%\n",
    "| 2. | 2024aa05010 | Himanshu Arora | 100%\n",
    "| 3. | 2024aa05111 | Sudeep Kumar | 100%\n",
    "| 4. | 2024aa05654 |  Mohit Saxena | 100%\n",
    "| 5. | TODO | TODO | 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62430148-5677-4dfa-b26b-3ad145e80cd9",
   "metadata": {},
   "source": [
    "<H1> Dataset Requirements </H1>\n",
    "<H2>Objective<H2>\n",
    "\n",
    "    Build a Hybrid Retrieval-Augmented Generation (RAG) system combining dense vector retrieval, sparse keyword retrieval (BM25), and Reciprocal Rank Fusion (RRF) to answer questions from 500 Wikipedia articles. Evaluate using an automated framework with 100 generated questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16b2b1-5ed6-4c3f-8d17-1fed3f7bf051",
   "metadata": {},
   "source": [
    "<h2>Installing required Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71191e7-e05c-41c6-8fb0-8b28774d0498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.0 MB 3.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 3.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.0 MB 3.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.9/12.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.7/12.0 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.5/12.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.0/12.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.5/12.0 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/12.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.8/12.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.6/12.0 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.4/12.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.0/1.1 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.7 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.8/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.6/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece, safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.36.0 safetensors-0.7.0 sentencepiece-0.2.1 tokenizers-0.22.2 transformers-4.57.6\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c8431fa-6f27-4098-bf12-3def50040561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.4.1-cp39-abi3-win_amd64.whl.metadata (7.3 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.3-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (4.14.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.23.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (0.22.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading pypika-0.50.0-py2.py3-none-any.whl.metadata (51 kB)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (1.73.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (0.16.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-35.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.11.5-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=24.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.33.4-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.7.1-cp312-cp312-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading chromadb-1.4.1-cp39-abi3-win_amd64.whl (21.4 MB)\n",
      "   ---------------------------------------- 0.0/21.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/21.4 MB 3.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.3/21.4 MB 3.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.8/21.4 MB 3.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.4/21.4 MB 3.1 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.9/21.4 MB 2.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 3.7/21.4 MB 3.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 4.5/21.4 MB 3.0 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 5.0/21.4 MB 3.0 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 5.8/21.4 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 6.6/21.4 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 7.3/21.4 MB 3.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 8.1/21.4 MB 3.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 8.9/21.4 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 10.0/21.4 MB 3.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 10.7/21.4 MB 3.5 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 11.8/21.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 12.8/21.4 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 13.6/21.4 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 14.7/21.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 15.5/21.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 16.3/21.4 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 17.3/21.4 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 18.1/21.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 18.6/21.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 19.4/21.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 20.2/21.4 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 20.7/21.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 21.4/21.4 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl (150 kB)\n",
      "Downloading build-1.4.0-py3-none-any.whl (24 kB)\n",
      "Downloading kubernetes-35.0.0-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.2.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.23.2-cp312-cp312-win_amd64.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/13.5 MB 3.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.3/13.5 MB 3.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.1/13.5 MB 3.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.9/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.7/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.5/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.2/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.0/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.8/13.5 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.3/13.5 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.9/13.5 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.9/13.5 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.7/13.5 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.5/13.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.5/13.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.3/13.5 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.1/13.5 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.5/13.5 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "Downloading orjson-3.11.5-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading pybase64-1.4.3-cp312-cp312-win_amd64.whl (35 kB)\n",
      "Downloading pypika-0.50.0-py2.py3-none-any.whl (60 kB)\n",
      "Downloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading httptools-0.7.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Downloading protobuf-6.33.4-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading watchfiles-1.1.1-cp312-cp312-win_amd64.whl (288 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pypika, durationpy, pyreadline3, pyproject_hooks, pybase64, protobuf, orjson, oauthlib, mmh3, importlib-resources, httptools, bcrypt, backoff, watchfiles, uvicorn, requests-oauthlib, posthog, opentelemetry-proto, opentelemetry-api, humanfriendly, googleapis-common-protos, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, coloredlogs, opentelemetry-sdk, onnxruntime, sentence-transformers, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "Successfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.4.0 chromadb-1.4.1 coloredlogs-15.0.1 durationpy-0.10 googleapis-common-protos-1.72.0 httptools-0.7.1 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-35.0.0 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 orjson-3.11.5 posthog-5.4.0 protobuf-6.33.4 pybase64-1.4.3 pypika-0.50.0 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 sentence-transformers-5.2.0 uvicorn-0.40.0 watchfiles-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\stanh\\anaconda3\\Lib\\site-packages\\~crypt'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "streamlit 1.37.1 requires protobuf<6,>=3.20, but you have protobuf 6.33.4 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.0.0 which is incompatible.\n",
      "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df9625a9-3b1f-43a0-bbdc-3edc22c6981a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics\n",
      "Category  Physics\n",
      "Titles  ['Physics', 'Atominstitute', 'Edge states', 'Electrostatic solitary wave', 'Frenesy (physics)', 'Haloscope (physics)', 'HUN-REN Wigner Research Centre for Physics', 'Joaquim da Costa Ribeiro', 'Missile lofting', 'Modern physics', 'Naïve physics', 'Negative air ions', 'Nottingham effect', 'Nucleation', 'Perfect fluid', 'Physics of Life', 'Plasmaron', 'Quasi-isodynamic stellarator', 'SDSS J120136.02+300305.5', 'Shockwave cosmology', 'Surface stress', 'Synchronous lateral excitation', 'Thermal energy', 'Toroidal solenoid', 'Wohlfarth Lectureship']\n",
      "\n",
      "Chemistry\n",
      "Category  Chemistry\n",
      "Titles  ['Chemistry', 'Actinide chemistry', 'Allotropy', 'Alloy', 'Amateur chemistry', 'Arens–van Dorp synthesis', 'Astrochemistry', 'Atmospheric chemistry', 'Atom', 'Biliprotein', 'Bioconcentration', 'Biophysical chemistry', 'Bittern (salt)', 'Building block (chemistry)', 'C1 chemistry', 'Calconcarboxylic acid', 'Carbodiphosphoranes', 'Carryover effect', 'The central science', 'Charged aerosol detector', 'Chemical bath deposition', 'Chemical biology', 'Chemical compound', 'Chemical element', 'Chemical equation', 'Chemical free', 'Chemical library', 'Chemical reaction', 'Chemical similarity', 'Chemical state', 'Chemical synthesis', 'Chemical technologist', 'Chemophobia', 'Chemoproteomics', 'Chirgwin–Coulson weights', 'Chromogen', 'Clandestine chemistry', 'Clay chemistry', 'Colloidal probe technique', 'Compliance constants', 'Compound Interest (website)', 'Congener (chemistry)', 'Cononsolvency', 'Core–shell semiconductor nanocrystal', 'Corrosion inhibitors for the petroleum industry', 'Crossover experiment (chemistry)', 'Crystal chemistry', 'Crystallography', 'Cyclosiloxane', 'Dark oxygen', 'Decay technique', 'DePriester chart', 'Direct reduction', 'Double layer forces', 'Electroconductive carbon black', 'Electrolysed water', 'Energy-rich species', 'Environmental chemistry', 'Equivalent weight', 'Estimated maximum possible concentration', 'Eutectic system', 'Field effect (chemistry)', 'Forensic chemistry', 'Free element', 'Geometry index', 'Gilchrist–Thomas process', 'Glossary of chemistry terms', 'C-glycosyl tryptophan', 'Green chemistry', 'Grupo Fertiberia', 'InChIKey', 'Intrinsic DNA fluorescence', 'Ioliomics', 'Landolt–Börnstein', 'Lewis acidic antimony compounds', 'Liquid nitrogen wash', 'Magnetochemistry', 'Mathematical chemistry', 'Mechanochemistry', 'Mental gland', 'Metal assisted chemical etching', 'Methane functionalization', 'Micro-X-ray fluorescence', 'Microfluidic cell culture', 'Microscale chemistry', 'Microsegregation', 'Mixed oxidant', 'Mixture', 'Molecule', 'Nanochemistry', 'Natural product', 'Negative air ions', 'Nuclear chemistry', 'Nucleation', 'Organic chemistry', 'Organolithium chemistry', 'Particle aggregation', 'Particle deposition', 'Random sequential adsorption', 'Phenol sulfur transferase deficiency', 'Philosophy of chemistry', 'Phosphorimidazolide', 'Photochemistry', 'Photopharmacology', 'Phytochemistry', 'Pressure-induced hydration', 'Probico', 'Radioanalytical chemistry', 'Rayleigh fractionation', 'Scale (chemistry)', 'School of Molecular Sciences', 'Shape of the atomic nucleus', 'Single-cell nanoencapsulation', \"Sinner's circle\", 'Soft chemistry', 'Solid-state electrolyte', 'Sonochemistry', 'Stable phosphorus radicals', 'Stereochemistry', 'Structural chemistry', 'Superelectrophilic anion', 'Superplasticizer', 'Supramolecular chemistry', 'Supramolecular coordination complex', 'Systems chemistry', 'Theoretical chemistry', 'Timeline of plastic development', 'TOP Assay', 'Triboluminescence', 'Wet chemistry']\n",
      "\n",
      "Biology\n",
      "Category  Biology\n",
      "Titles  ['Biology', 'Biologist', 'Bibliography of encyclopedias: biology', 'Bioactive terrarium', 'Bioliteracy', 'Biological constraints', 'Biology of romantic love', 'Biospeleology', 'Cancer exodus hypothesis', 'Chlororespiration', 'Dermestarium', 'Endogeny (biology)', 'Erinacin', 'Excretion', 'Functional information', 'High throughput biology', 'Interdigitation', 'Plasmagene', 'Poison exon', 'Polylecty', 'Spatial biology', 'Tokogeny', 'Universality–diversity paradigm']\n",
      "\n",
      "Mathematics\n",
      "Category  Mathematics\n",
      "Titles  ['Mathematics', 'Constructions of magic squares', 'Language of mathematics', 'Linear range', 'Synthetic mathematics', 'Zonotope']\n",
      "\n",
      "Computer_science\n",
      "Category  Computer_science\n",
      "Titles  ['Computer science', 'Glossary of computer science', 'Outline of computer science', 'Agnostic (data)', 'Boolean', 'Catalytic computing', 'Computational gastronomy', 'Computer science in sport', 'Filter and refine', 'Learnable function', 'LinkML', 'List of abstractions (computer science)', 'Peripheral', 'Prefetching', 'Technology transfer in computer science', 'Thermodynamic computing', 'Transition (computer science)', 'Sara L. Uckelman']\n",
      "\n",
      "Artificial_intelligence\n",
      "Category  Artificial_intelligence\n",
      "Titles  ['Artificial intelligence', 'List of artificial intelligence journals', '2024–2026 global memory supply shortage', 'Actor-critic algorithm', 'Admissible heuristic', 'Agentive logic', '.ai', 'AI agent', 'AI alignment', 'AI anthropomorphism', 'AI browser', 'AI data center', 'AI literacy', 'AI nationalism', 'AI Overviews', 'AI safety', 'AI veganism', 'AI washing', 'AI-assisted software development', 'AI-complete', 'AIOps', 'Algorithmic probability', 'Ameca (robot)', 'And–or tree', 'Answer engine optimization', 'Argumentation framework', 'Artificial brain', 'Artificial consciousness', 'Artificial general intelligence', 'Timeline of artificial intelligence risks in global finance', 'Artificial intelligence and elections', 'Artificial intelligence arms race', 'Artificial intelligence controversies', 'Artificial intelligence in education', 'Artificial intelligence in physical therapy', 'Artificial intelligence in spirituality', 'Artificial intelligence in the 2024 United States presidential election', 'Artificial intelligence of things', 'Artificial intelligence optimization', 'Artificial intimacy', 'Artificial Inventor Project', 'Artificial psychology', 'Artificial reproduction', 'Artificial wisdom', 'ASR-complete', 'Attributional calculus', 'Autognostics', 'Automated machine learning', 'Automated Mathematician', 'Automated medical scribe', 'Automated negotiation', 'Autonomic networking', 'Autonomous agent', 'AZFinText', 'Bayesian programming', 'Anna Becker', 'Behavior informatics', 'Belief–desire–intention model', 'Biohybrid system', 'Brain technology', 'Business process automation', 'CarynAI', 'Case-based reasoning', 'CHAOS (chess)', 'Character computing', 'Class activation mapping', 'Cognitive computing', 'Cognitive Digital Network', 'Cognitive philology', 'Coherent extrapolated volition', 'Commonsense knowledge (artificial intelligence)', 'Competition in artificial intelligence', 'Computational heuristic intelligence', 'Computational humor', 'Computational intelligence', 'Computer audition', 'Concurrent MetateM', 'Connectionist expert system', 'DABUS', 'Data annotation', 'Deadbot', 'Deep Learning Anti-Aliasing', 'Deep Learning Super Sampling', 'Description logic', 'Dia (web browser)', 'Diella (AI system)', 'Data Science and Predictive Analytics', 'Dynamic epistemic logic', 'Elements of AI', 'Embodied agent', 'Embodied cognitive science', 'Emergent algorithm', 'Empowerment (artificial intelligence)', 'Enterprise cognitive system', 'Environmental impact of artificial intelligence', 'Epistemic modal logic', 'Ethics of artificial intelligence', 'Evolutionary developmental robotics', 'Explainable artificial intelligence', 'Extremal optimization', 'The Fable of Oscar', 'Feedback neural network', 'Fuzzy agent', \"Gabbay's separation theorem\", 'Galaxy AI', 'Game theory', 'Gender digital divide', 'Genesis Mission', 'Gibberlink', 'Gödel machine', 'GOLOG', 'Google AI Mode', 'Google Clips', 'Google Research', 'Grammar systems theory', 'Graphics processing unit', 'Hardware for artificial intelligence', 'Hello World: How to be Human in the Age of the Machine', 'Hierarchical control system', 'Histogram of oriented displacements', 'Human Problem Solving', 'Human-AI interaction', 'Human-centered AI', 'Hybrid intelligent system', 'Incremental heuristic search', 'INDIAai', 'Information space analysis', 'Intelligent agent', 'Intelligent control', 'Intelligent database', 'Intelligent decision support system', 'Intelligent word recognition', 'Intrinsic motivation (artificial intelligence)', 'Is This What We Want?', 'K-line (artificial intelligence)', 'KAoS', 'Knowledge compilation', 'Knowledge cutoff', 'Knowledge level', 'Knowledge-based configuration', 'Knowledge-based recommender system', 'Knowledge-based systems', 'Language/action perspective', 'Last Mile (artificial intelligence)', 'Learnable function', \"Liar's dividend\", 'Lifelong Planning A*', 'List of programming languages for artificial intelligence', 'Lists of open-source artificial intelligence software', 'Machine perception', 'MAUVE (metric)', 'Means–ends analysis', 'Mechanistic interpretability', \"Medical School Admissions: Report of a formal investigation into St. George's Hospital Medical School (1988)\", 'MediSafe controversy', 'Military applications of artificial intelligence', 'Mindpixel', 'MindsDB', 'Mode collapse', 'Moral outsourcing', 'NASA AI Assisted-Air Quality Monitoring Project', 'Neural computation', 'Neural scaling law', 'Neuro-symbolic AI', 'Neurorobotics', 'Non-human', 'Nouvelle AI', 'Operation Serenata de Amor', 'Operational artificial intelligence', 'Organoid intelligence', 'Pattern theory', 'Pedagogical agent', 'Percept (artificial intelligence)', 'Personality computing', 'Personoid', 'Perusall', 'POP-11', 'Principle of rationality', 'Problem solving', 'Progress in artificial intelligence', 'Psychology of reasoning', 'Qloo', 'Quantum artificial life', 'Reasoning model', 'Recursive self-improvement', 'Resisting AI', 'Robotic process automation', 'Schema-agnostic databases', 'Self-management (computer science)', 'Singularity studies', 'Situated', 'Situated approach (artificial intelligence)', 'Smart object', 'Software agent', 'Space-based data center', 'Sparkles emoji', 'Spreading activation', 'STIT logic', 'Superintelligence ban', 'Supermind AI', 'SUPS', 'Syman', 'Symbol level', 'Symbolic artificial intelligence', 'TensorFlow Hub', 'Alexander Y. Tetelbaum', 'Toy problem', 'Trupeer', 'UAE Strategy for Artificial Intelligence', 'United States Tech Force', 'Universal psychometrics', 'Video Super Resolution', 'Virtual intelligence', 'Wadhwani Institute for Artificial Intelligence', 'Way of the Future', 'Weak artificial intelligence', 'Web intelligence', 'Wetware (brain)', 'Wetware computer', 'Winner-take-all in action selection', 'Workplace impact of artificial intelligence', 'Wumpus world', 'Zeuthen strategy']\n",
      "\n",
      "Machine_learning\n",
      "Category  Machine_learning\n",
      "Titles  ['Machine learning', 'Outline of machine learning', '80 Million Tiny Images', 'A Logical Calculus of the Ideas Immanent in Nervous Activity', 'Accelerated Linear Algebra', 'Action model learning', 'Active learning (machine learning)', 'Adversarial machine learning', 'AI data center', 'AIOps', 'AIXI', 'Algorithm selection', 'Algorithmic bias', 'Algorithmic inference', 'AlphaChip (controversy)', 'Anomaly detection', 'Aporia (company)', 'Apprenticeship learning', 'Artificial intelligence in hiring', 'Astrostatistics', 'Attention (machine learning)', 'Audio inpainting', 'Automated decision-making', 'Automated machine learning', 'Automation in construction', 'Bag-of-words model', 'Ball tree', 'Base rate', 'Bayesian interpretation of kernel regularization', 'Bayesian learning mechanisms', 'Bayesian optimization', 'Bayesian regret', 'Bayesian structural time series', 'Bias–variance tradeoff', 'Binary classification', 'Bioserenity', 'Bradley–Terry model', 'Category utility', 'CIML community portal', 'Claude (language model)', 'Cognitive robotics', 'Concept drift', 'Conditional random field', 'Confusion matrix', 'Contrastive Language-Image Pre-training', 'Cost-sensitive machine learning', 'Coupled pattern learner', 'Croissant (metadata format)', 'Cross-entropy method', 'Cross-validation (statistics)', 'Curse of dimensionality', 'Data augmentation', 'Data exploration', 'Data preprocessing', 'Data-driven astronomy', 'Data-driven model', 'Decision list', 'Decision tree pruning', 'Deep tomographic reconstruction', 'Developmental robotics', 'Discovery system (artificial intelligence)', 'Document classification', 'Domain adaptation', 'Double descent', 'Eager learning', 'EfficientNet', 'ELMo', 'EM algorithm and GMM model', 'Embedding (machine learning)', 'Empirical dynamic modeling', 'Empirical risk minimization', 'Energy-based model', 'Equalized odds', 'Evaluation of binary classifiers', 'Evolvability (computer science)', 'Expectation propagation', 'Explanation-based learning', 'Exploration–exploitation dilemma', 'Fairness (machine learning)', 'Feature (machine learning)', 'Feature engineering', 'Feature hashing', 'Feature learning', 'Feature scaling', 'Federated learning', 'Fine-tuning (deep learning)', 'Flow-based generative model', 'Flux (machine-learning framework)', 'Force control', 'Formal concept analysis', 'Generalized additive model for location, scale and shape', 'Generative artificial intelligence', 'Generative model', 'Geometric feature learning', 'Glossary of artificial intelligence', 'Google Colab', 'Google Research', 'Granular computing', 'Grokking (machine learning)', 'H (company)', 'H2O (software)', 'Hallucination (artificial intelligence)', 'Hidden layer', 'Hierarchical navigable small world', 'Hierarchical Risk Parity', 'Highway network', 'Hugging Face', 'Human-in-the-loop', 'Hyperparameter (machine learning)', 'Hyperparameter optimization', 'In-context learning (natural language processing)', 'Inauthentic text', 'Inception score', 'Inductive bias', 'Inductive probability', 'Inductive programming', 'Inferential theory of learning', 'Instance selection', 'Instance-based learning', 'Intelligent automation', 'Isotropic position', 'JAX (software)', 'Journal of Machine Learning Research', 'Kernel density estimation', 'Kernel embedding of distributions', 'Knowledge graph embedding', 'Knowledge integration', 'Kolmogorov-Arnold Networks', 'Labeled data', 'Lazy learning', 'Leakage (machine learning)', 'Learnable function', 'Learnable function class', 'Learning automaton', 'Learning curve (machine learning)', 'Learning rate', 'Learning to rank', 'Life-time of correlation', 'Linear predictor function', 'Linear separability', 'LLM-as-a-Judge', 'Local case-control sampling', 'LoRA (machine learning)', 'Lottery ticket hypothesis', 'Lyra (codec)', 'M-theory (learning framework)', 'Machine Learning (journal)', 'Machine Learning and Knowledge Extraction', 'Machine learning control', 'Machine learning in bioinformatics', 'Machine learning in earth sciences', 'Machine learning in physics', 'Machine learning in video games', 'Machine unlearning', 'Machine-learned interatomic potential', 'Manifold hypothesis', 'Manifold regularization', 'The Master Algorithm', 'Matchbox Educable Noughts and Crosses Engine', 'Matrix regularization', 'MAUVE (metric)', 'Maximum inner-product search', 'Mechanistic interpretability', 'Meta-Labeling', 'Meta-learning (computer science)', 'MLOps', 'MobileNet', 'Mode collapse', 'Model compression', 'Mountain car problem', 'Multi-armed bandit', 'Multi-task learning', 'Multimodal representation learning', 'Multimodal sentiment analysis', 'Multiple instance learning', 'Multiple-instance learning', 'Multiplicative weight update method', 'Multitask optimization', 'Multivariate adaptive regression spline', 'Native-language identification', 'Nature Machine Intelligence', 'Neural modeling fields', 'Neural network quantum states', 'Normalization (machine learning)', 'Novelty detection', 'Offline learning', 'Overfitting', 'Paraphrasing (computational linguistics)', 'Parity learning', 'Pattern language (formal languages)', 'Pattern recognition', 'Perceiver', 'Perception error model', 'PHerc. Paris. 4', 'Phi coefficient', 'Predictive learning', 'Predictive state representation', 'Preference learning', 'Prior knowledge for pattern recognition', 'Proactive learning', 'Proaftn', 'Probabilistic numerics', 'Probability matching', 'Product of experts', 'Products and applications of OpenAI', 'Programming by example', 'Prompt engineering', 'Proximal gradient methods for learning', 'Purged cross-validation', 'Pythia (machine learning)', 'Quantification (machine learning)', 'Quantum machine learning', 'Rabbit r1', 'Rademacher complexity', 'Random feature', 'Reasoning model', 'Reciprocal human machine learning', 'Relational data mining', 'Reparameterization trick', 'Right to explanation', 'Robot learning', 'Robotic process automation', 'ROCm', 'Rule induction', 'Sample complexity', 'Self-supervised learning', 'Semantic analysis (machine learning)', 'Semantic folding', 'Semi-supervised learning', 'Sequence labeling', 'Similarity learning', 'Socially assistive robot', 'Lynda Soderholm', \"Solomonoff's theory of inductive inference\", 'Spatial embedding', 'Spike-and-slab regression', 'Stability (learning theory)', 'Statistical learning theory', 'Statistical relational learning', 'Structural risk minimization', 'Structured sparsity regularization', 'Surrogate model', 'Symbolic regression', 'Tensor (machine learning)', 'TensorFlow Hub', 'Three-factor learning', 'Time series', 'Timeline of machine learning', 'Toronto Declaration', 'Transduction (machine learning)', 'Transfer learning', 'Ugly duckling theorem', 'Uncertain data', 'Under-fitting', 'Underfitting', 'Uniform convergence in probability', 'Universal portfolio algorithm', 'Upper Confidence Bound', 'VACUUM', 'Validation set', 'Vector database', 'Version space learning', 'Weak supervision', 'Weight initialization']\n",
      "\n",
      "Medicine\n",
      "Category  Medicine\n",
      "Titles  ['Medicine', 'Outline of medicine', '505(b)(2) regulatory pathway', 'Terminology of alternative medicine', 'Anti-aging medicine', 'Anti-asthmatic agent', 'Barostriction', 'Breastmilk medicine', 'Cancer exodus hypothesis', 'Clinical handover', 'Confocal endoscopy', 'Diabetes self-management', 'Dorsal pancreatic agenesis', 'Drone-Enhanced Emergency Medical Services', 'Electronic health record (Germany)', 'Follicular drug delivery', 'Intersex healthcare', 'Isotropic bands', 'KDM5C-related neurodevelopmental disorder', 'LAMA2 related congenital muscular dystrophy', 'Landarzt', 'LINKED syndrome', 'List of forms of alternative medicine', 'LY-2365109', 'Maibaron', 'Most Favored Nation Drug Pricing', \"Musicians' Medicine\", 'NAKO Health Study', 'Medical oddity', 'Pediatric endocrinology', 'Physical therapy for stroke rehabilitation', 'POCUS', 'Poison exon', 'RNU2-2 syndrome', 'RNU4-2 syndrome', 'Surgical clearance', 'Synthetic cannabinoid use disorder', 'Urinary anti-infective agent', 'Vestibular paroxysmia']\n",
      "\n",
      "Psychology\n",
      "Category  Psychology\n",
      "Titles  ['Psychology', 'Outline of psychology', 'Alarmism', 'Aphantasia', 'Belief congruence', 'Binocular disparity', 'Binocular vision', 'Biology of romantic love', 'Black fatigue', 'Cognitive immunization', 'Counterphobic attitude', 'Cybersexuality', 'Double-nail illusion', 'Folk economics', 'Fragile masculinity', 'Frequency illusion', 'Human-AI interaction', 'Identity disturbance', 'Impact of the COVID-19 pandemic on time perception', 'Limerence', 'Love addiction', 'Moral emotions', 'Musical escapism', 'Obsessive love', 'Passionate and companionate love', 'Perceptual vigilance', 'Psychiatry', 'Psychologist', 'Rapture anxiety', 'Resilience week', 'Reward theory of attraction', 'Rhyme-as-reason effect', 'Social buffering', 'Synthetic thinking', 'The Chicago School of Psychology', 'Ultra-realism', 'Western esotericism and psychology']\n",
      "\n",
      "Philosophy\n",
      "Category  Philosophy\n",
      "Titles  ['Philosophy', 'Outline of philosophy', 'De ente et essentia', 'Deaf philosophy', 'Hug (folklore)', 'Singularity studies', 'Sociology of philosophy', 'Synthetic thinking', 'Universal brotherhood']\n",
      "\n",
      "Economics\n",
      "Category  Economics\n",
      "Titles  ['Economics', 'Index of economics articles', 'Outline of economics', 'Economics in film', 'Freeriding (economics)', 'Economic impact analysis']\n",
      "\n",
      "Political_science\n",
      "Category  Political_science\n",
      "Titles  ['Political science', 'Outline of political science', 'History of political science', 'Politics of memory', 'Anti-elitism', 'Anti-politics', 'Becoming Activists in Global China', 'Benevolence and the Mandate of Heaven', 'Bio-index model', 'Biology and political orientation', 'Biology and political science', 'Biopower', 'Bipolarisation', 'The Birth of Biopolitics', 'Boundary problem (political science)', 'Bureau-shaping model', 'Bureaucracy', 'Bureaucratic drift', 'Bureaucratic inertia', 'Cameral science', 'CIRI Human Rights Data Project', 'Class struggle', 'Coalition committee', 'Coercion, Capital, and European States, AD 990–1992', 'Collegial body', 'Comparative political theory', 'Comparative politics', 'Comparative Study of Electoral Systems', 'Computational politics', 'Constructivism (ethnic politics)', 'Critical juncture theory', 'Cultural imperialism', 'Deliberatorium', 'Democracy-Dictatorship Index', 'Digital era governance', 'Dual loyalty', 'East European Politics', 'Election science', 'Electoral abstention in France', 'Elite theory', 'Elitism', 'Environmental politics', 'Essex School of discourse analysis', 'The Establishment (Pakistan)', 'Ethnosymbolism', 'Exit, Voice, and Loyalty Model', 'Extended order', 'Feminist political theory', \"Foucault's lectures at the Collège de France\", 'Gateway belief model', 'Genopolitics', 'Gladstone Professor of Government', 'Global Environment and Trade Study', 'Heresthetic', 'History of terrorism', 'Horseshoe theory', 'Hybrid warfare', 'Imperial boomerang', 'India Quarterly', 'Inherent bad faith model', 'Institutional analysis', 'Institutional analysis and development framework', 'International Center for Black Sea Studies', 'International Contact Group', 'International institutes on political management', 'Issue ownership', 'Judicial Common Space', 'Latin American Public Opinion Project', 'Leadership spill', 'Legal opportunity structure', 'Level of analysis', 'Jenny M. Lewis', \"Liar's dividend\", 'Linked fate', 'Martin–Quinn score', 'Mierscheid law', 'Minimal effects hypothesis', 'Moderation theory', 'Modern Studies', 'Moral high ground', 'Multiple streams framework', 'Multistakeholder governance', 'Nationalism and gender', 'Neuropolitics', 'New generation warfare', 'NOMINATE (scaling method)', 'Notional election results', 'Nurturant parent model', 'Open government', 'The Origins of Political Order', 'Peace–industrial complex', 'Perestroika Movement (political science)', 'Policy analysis', 'Policy entrepreneur', 'Policy monitoring', 'Policy network analysis', 'Policy studies', 'Political climate', 'Political cognition', 'Political communication', 'Political decay', 'Political forecasting', 'Political groups of the European Parliament', 'Political identity', 'Political linguistics', 'Political methodology', 'Political ontology', 'Political opportunity', 'Political polarization', 'Political recruitment model', 'Political ReviewNet', 'Political stability', 'Politicisation', 'The Politics of Uncertainty', 'Post-democracy', 'Private defense agency', 'Private-collective model of innovation', 'Process tracing', 'Progress', 'Project Troy', 'Public', 'Public comment', 'Public engagement', 'Public opinion', 'Public policy', 'Public speaking', 'Regulatory capitalism', 'Revolving door effect', 'Rhetorical presidency', 'Security, Territory, Population', 'Selectorate theory', 'Self-expression values', 'Serfdom in Tibet controversy', 'Sincere favorite criterion', 'Social choice theory', 'State formation', 'Statecraft', 'Stationary bandit theory', 'Strategic urban planning', 'Strict father model', 'Systemic wars theory', 'Systems theory in political science', 'Tryphé', 'Turncoat', 'Twitter diplomacy', 'The Use of Knowledge in Society', 'Valence issue', 'Voter turnout', 'World Social Capital Monitor', 'World Values Survey']\n",
      "\n",
      "Indian_history\n",
      "Category  Indian_history\n",
      "Titles  []\n",
      "\n",
      "World_War_II\n",
      "Category  World_War_II\n",
      "Titles  ['Outline of World War II', '1945 Resko Przymorskie Dornier Do 24 crash', 'Anti-Partisan action in Srem (1944)', 'Attack on the battleship Tirpitz by submarine K-21', 'Axis powers', 'Battle of Hucisko', 'Battle of Jaktorów', 'Brickendonbury', 'Chetnik attack on the Užice Republic', 'ORP Czapla', 'Freemasonry during World War II', 'Yulii Garbuzov', 'The Ghost Division', 'James Goodwin Hall', 'John Charles Francis Holland', 'Meitei novel', 'Eric Peter Molyneux', 'Names of the Second World War', 'Naval battles of Narvik', 'Norman Crockatt', 'USCGC Northland (WPG-49)', 'Open city', 'Operation SUSSEX', 'Operation Winterende', 'Peace efforts during World War II', 'ORP S-3', 'World War II', 'World War II combatives']\n",
      "\n",
      "Geography\n",
      "Category  Geography\n",
      "Titles  ['Geography', 'Outline of geography', 'Bioregion', 'Distance decay', 'Economic restructuring', 'Exploration', 'Extreme environment', 'Geo-literacy', 'Geo-replication', 'Geocriticism', 'Geographic contiguity', 'Geography of aging', 'Geohumanities', 'Governmentality', 'International date line in Judaism', 'Internet geography', 'Landlocked developing countries', 'Rank–size distribution', 'Recueil de Voyages et de Mémoires', 'Religion and geography', 'Shoreline segmentation', 'Small Island Developing States', 'Solar equator', 'Spatial citizenship', 'Spatial justice', 'Spatial mismatch', 'Surroundings']\n",
      "\n",
      "Countries\n",
      "Category  Countries\n",
      "Titles  ['Country', 'List of country groupings', 'Gaelic Ireland', 'List of modern great powers']\n",
      "\n",
      "Architecture\n",
      "Category  Architecture\n",
      "Titles  ['Architecture', 'Index of architecture articles', '40 year structural inspections', 'Adaptive architecture', 'Anarchist architecture', 'Architectural ensemble', 'Architectural management', 'Architecture in Middle-earth', 'Architecture of Star Wars', 'Architextiles', 'Artificial intelligence in architecture', 'Atmosphere (architecture and spatial design)', 'Basket-handle arch', 'Bionic architecture', 'Building information modeling', 'Building performance simulation', 'Civil basilica', 'Conical roof', 'Coping (architecture)', 'Corporate architecture', 'Curved structures', 'Architectural drawing', 'Educational architecture', 'Ephemeral architecture', 'EUICC', 'Expression (architecture)', 'Free plan', 'Industrial architecture', 'Interactive architecture', 'Iranian Architecture Documentary', 'Lamella (structure)', 'LGBTQ architectural contributions', 'Lifting boss', 'Membrane structure', 'Architectural model', 'Morphology (architecture and engineering)', 'Museum architecture', 'Open-source architecture', 'Organizational space', 'Overlay architecture', 'Paned window (architecture)', 'Parametric design', 'Parametric thinking', 'Performative architecture', 'Post-occupancy evaluation', 'Architectural propaganda', 'Real estate development', 'Regia (architecture)', 'Architectural reprography', 'Resilience (engineering and construction)', 'Scagliola', 'Scarab (fraternity)', 'Sciography', 'Separating arch', 'Site-specific architecture', 'Slipcover (architecture)', 'Sonata (building design software)', 'Space (architecture)', 'Space architecture', 'Standoff distance', 'Sustainable design standards', 'Architectural technology', 'Temporary appropriation', 'Totalitarian architecture', 'Traditional architecture']\n",
      "\n",
      "Music\n",
      "Category  Music\n",
      "Titles  ['Music', 'Index of music articles']\n",
      "\n",
      "Films\n",
      "Category  Films\n",
      "Titles  []\n",
      "\n",
      "Literature\n",
      "Category  Literature\n",
      "Titles  ['Literature', 'Outline of literature', 'Allusion', 'Anticipatory plagiarism', 'Comedy of menace', 'Domestic realism', 'Film adaptation', 'Futurism (literature)', 'Indie literature', 'Intelligence literature', 'Interlingue literature', 'Literary language', 'Liberature', 'Literary dunce', 'Outdoor literature', 'Poetics', 'Popular history', 'Sociology of literature', 'Stylistics', 'Western canon']\n",
      "\n",
      "Sports\n",
      "Category  Sports\n",
      "Titles  ['Sport']\n",
      "\n",
      "Cricket\n",
      "Category  Cricket\n",
      "Titles  ['Cricket', 'Batting (cricket)', 'Bowling (cricket)', 'Captain (cricket)', 'Crease (cricket)', 'Cricket ball', 'Cricket bat', 'Cricket clothing and equipment', 'Cricket field', 'Cricket pitch', 'Dismissal (cricket)', 'Extra (cricket)', 'Fielding (cricket)', 'Forms of cricket', 'Glossary of cricket terms', 'History of cricket', 'Innings', 'International Cricket Council', 'Laws of Cricket', 'Over (cricket)', 'Result (cricket)', 'Run (cricket)', 'Scorer', 'Umpire (cricket)', 'Wicket', 'Wicket-keeper', \"Women's cricket\"]\n",
      "\n",
      "Association_football\n",
      "Category  Association_football\n",
      "Titles  ['Association football', 'Outline of association football', 'Football economics', 'Football trafficking', 'Geography of association football', 'Barış Karabıyık', 'Names for association football']\n",
      "\n",
      "Astronomy\n",
      "Category  Astronomy\n",
      "Titles  ['Glossary of astronomy', 'Outline of astronomy', '96P sungrazer family', 'Alaknanda Galaxy', 'Astronomer', 'Astronomy', 'Astrotourism', 'Cygnus Molecular Nebula Complex', 'Data-driven astronomy', 'Dust astronomy', 'Elephant trunk (astronomy)', 'Exometeorology', 'Exoplanet Explorers', 'First point of Aries', 'Geodesy', 'Giuseppe Donatiello', 'Gravitational memory effect', 'Half-month', 'Harvard Plate Stacks', 'Huihui Lifa', 'IAU (1976) System of Astronomical Constants', 'Instrumental magnitude', \"Kathryn's Wheel\", 'La Sociedad Interamericana de Astronomía en la Cultura', 'List of galaxies by surface brightness', 'List of Indian astronomical treatises', 'Meitei astronomy', 'Monochrome astrophotography techniques', 'Multi-messenger astronomy', 'Jack B. Newton', 'Pale Blue Dot', 'Periodicity of solar eclipses', 'Planet Patrol (project)', 'Planetary coordinate system', 'Pycnonuclear fusion', 'Radio Galaxy Zoo', 'Regius Professor of Astronomy (Edinburgh)', 'SAGES Legacy Unifying Globulars and GalaxieS Survey', 'Pranav Sharma', 'Shockwave cosmology', 'SigMF', 'SN 1990E', 'SN 2018gv', 'Solar longitude', 'Solar radio emission', 'Songline', 'Spiral arm', 'Stellar archaeology', 'Stellar engulfment', 'Stellar flyby', 'Supergalactic plane', 'Synodic day', 'Tidal downsizing', 'Vicarious Hypothesis', 'Yajnavalkya 95 Years Cycle']\n",
      "\n",
      "Environment\n",
      "Category  Environment\n",
      "Titles  []\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fixed_count': 200,\n",
       " 'rejections': {'too_short_138': 1,\n",
       "  'too_short_112': 1,\n",
       "  'too_short_199': 1,\n",
       "  'empty_extract': 7,\n",
       "  'too_short_107': 1,\n",
       "  'too_short_66': 1,\n",
       "  'too_short_116': 1,\n",
       "  'too_short_108': 1,\n",
       "  'too_short_126': 1,\n",
       "  'too_short_195': 1,\n",
       "  'too_short_46': 2,\n",
       "  'too_short_120': 1,\n",
       "  'too_short_155': 1,\n",
       "  'too_short_103': 1,\n",
       "  'too_short_110': 1,\n",
       "  'too_short_144': 2,\n",
       "  'too_short_93': 1,\n",
       "  'too_short_142': 1,\n",
       "  'too_short_163': 2,\n",
       "  'too_short_57': 1,\n",
       "  'too_short_113': 1,\n",
       "  'too_short_115': 1,\n",
       "  'too_short_128': 1,\n",
       "  'too_short_182': 1,\n",
       "  'too_short_94': 1},\n",
       " 'out': 'data/fixed_urls.json'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NOTE: Please run only once, to generate the fixed URLs\n",
    "## Prepare fixed Wikipedia URLs, covering diverse topic\n",
    "# Round-robin across categories to enforce diversity\n",
    "from src.build.build_fixed_urls import build_fixed_urls\n",
    "fixedUrl = build_fixed_urls()\n",
    "fixedUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "778daa25-0a21-4d64-82b9-fe9066d418d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_count': 300,\n",
       " 'loops': 12,\n",
       " 'rejections': {'too_short_190': 2,\n",
       "  'too_short_50': 2,\n",
       "  'too_short_137': 3,\n",
       "  'too_short_171': 2,\n",
       "  'too_short_98': 2,\n",
       "  'too_short_94': 4,\n",
       "  'too_short_138': 2,\n",
       "  'too_short_122': 4,\n",
       "  'too_short_109': 2,\n",
       "  'too_short_64': 1,\n",
       "  'too_short_166': 2,\n",
       "  'too_short_117': 2,\n",
       "  'too_short_30': 1,\n",
       "  'too_short_18': 3,\n",
       "  'disambiguation': 30,\n",
       "  'too_short_191': 1,\n",
       "  'too_short_67': 2,\n",
       "  'too_short_22': 2,\n",
       "  'too_short_176': 1,\n",
       "  'too_short_55': 2,\n",
       "  'too_short_158': 2,\n",
       "  'too_short_192': 2,\n",
       "  'too_short_83': 1,\n",
       "  'too_short_75': 1,\n",
       "  'too_short_52': 7,\n",
       "  'too_short_26': 5,\n",
       "  'too_short_182': 2,\n",
       "  'too_short_159': 2,\n",
       "  'too_short_93': 2,\n",
       "  'too_short_97': 2,\n",
       "  'too_short_48': 1,\n",
       "  'too_short_87': 2,\n",
       "  'too_short_32': 3,\n",
       "  'too_short_139': 2,\n",
       "  'too_short_17': 1,\n",
       "  'too_short_69': 1,\n",
       "  'too_short_43': 3,\n",
       "  'too_short_175': 2,\n",
       "  'too_short_91': 3,\n",
       "  'too_short_121': 2,\n",
       "  'too_short_73': 2,\n",
       "  'too_short_21': 2,\n",
       "  'too_short_74': 1,\n",
       "  'too_short_78': 1,\n",
       "  'too_short_16': 1,\n",
       "  'too_short_42': 3,\n",
       "  'too_short_107': 3,\n",
       "  'too_short_125': 2,\n",
       "  'too_short_66': 4,\n",
       "  'too_short_29': 1,\n",
       "  'too_short_68': 2,\n",
       "  'too_short_38': 4,\n",
       "  'too_short_118': 2,\n",
       "  'too_short_65': 3,\n",
       "  'too_short_151': 1,\n",
       "  'too_short_63': 2,\n",
       "  'too_short_152': 3,\n",
       "  'too_short_120': 2,\n",
       "  'too_short_95': 1,\n",
       "  'too_short_71': 3,\n",
       "  'too_short_187': 1,\n",
       "  'too_short_174': 2,\n",
       "  'too_short_148': 2,\n",
       "  'too_short_39': 1,\n",
       "  'too_short_59': 2,\n",
       "  'too_short_86': 1,\n",
       "  'too_short_128': 2,\n",
       "  'too_short_140': 3,\n",
       "  'too_short_149': 1,\n",
       "  'too_short_70': 1,\n",
       "  'too_short_89': 1,\n",
       "  'too_short_34': 1,\n",
       "  'too_short_167': 1,\n",
       "  'too_short_153': 3,\n",
       "  'too_short_160': 2,\n",
       "  'too_short_24': 1,\n",
       "  'too_short_106': 1,\n",
       "  'too_short_134': 2,\n",
       "  'too_short_76': 1,\n",
       "  'too_short_57': 1,\n",
       "  'too_short_23': 2,\n",
       "  'too_short_179': 1,\n",
       "  'too_short_136': 1,\n",
       "  'too_short_35': 1,\n",
       "  'too_short_126': 2,\n",
       "  'too_short_99': 2,\n",
       "  'too_short_104': 1,\n",
       "  'too_short_46': 1,\n",
       "  'too_short_60': 1,\n",
       "  'too_short_51': 2,\n",
       "  'too_short_133': 1,\n",
       "  'too_short_150': 1,\n",
       "  'too_short_181': 2,\n",
       "  'too_short_105': 3,\n",
       "  'too_short_33': 2,\n",
       "  'too_short_180': 1,\n",
       "  'too_short_145': 1,\n",
       "  'too_short_31': 1,\n",
       "  'too_short_62': 2,\n",
       "  'too_short_40': 1,\n",
       "  'too_short_183': 1,\n",
       "  'too_short_90': 2,\n",
       "  'too_short_164': 1,\n",
       "  'too_short_124': 1,\n",
       "  'too_short_47': 2,\n",
       "  'too_short_186': 1,\n",
       "  'too_short_144': 1,\n",
       "  'too_short_185': 1,\n",
       "  'too_short_54': 2,\n",
       "  'too_short_45': 1,\n",
       "  'too_short_84': 1,\n",
       "  'too_short_13': 1,\n",
       "  'too_short_19': 1,\n",
       "  'too_short_114': 2,\n",
       "  'too_short_146': 1,\n",
       "  'too_short_79': 1,\n",
       "  'too_short_132': 2,\n",
       "  'too_short_92': 1,\n",
       "  'too_short_170': 1,\n",
       "  'too_short_112': 2,\n",
       "  'too_short_20': 1,\n",
       "  'too_short_157': 1,\n",
       "  'too_short_44': 1,\n",
       "  'too_short_96': 1,\n",
       "  'too_short_110': 1,\n",
       "  'too_short_102': 1,\n",
       "  'too_short_162': 2,\n",
       "  'too_short_156': 1,\n",
       "  'too_short_116': 1,\n",
       "  'too_short_28': 1,\n",
       "  'too_short_119': 1,\n",
       "  'too_short_37': 1,\n",
       "  'too_short_103': 1},\n",
       " 'errors': {},\n",
       " 'out': 'data/random_urls.json'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Set (300 URLs), minimum 200 words per page. These should change every time the system is rebuilt/indexed.\n",
    "from src.build.build_random_urls import build_random_urls\n",
    "build_random_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2faf6f1-1666-4974-ba9b-fc0bd9a7499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "942fe29c-1038-45fd-9b8e-9e32adc9e8cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25/500 URLs | pages_ok=25 | chunks=412\n",
      "Processed 50/500 URLs | pages_ok=50 | chunks=736\n",
      "Processed 75/500 URLs | pages_ok=75 | chunks=1103\n",
      "Processed 100/500 URLs | pages_ok=100 | chunks=1379\n",
      "Processed 125/500 URLs | pages_ok=125 | chunks=1758\n",
      "Processed 150/500 URLs | pages_ok=150 | chunks=1906\n",
      "Processed 175/500 URLs | pages_ok=175 | chunks=2331\n",
      "Processed 200/500 URLs | pages_ok=200 | chunks=2589\n",
      "Processed 225/500 URLs | pages_ok=225 | chunks=2682\n",
      "Processed 250/500 URLs | pages_ok=250 | chunks=2784\n",
      "Processed 275/500 URLs | pages_ok=275 | chunks=2889\n",
      "Processed 300/500 URLs | pages_ok=300 | chunks=3035\n",
      "Processed 325/500 URLs | pages_ok=325 | chunks=3182\n",
      "Processed 350/500 URLs | pages_ok=350 | chunks=3280\n",
      "Processed 375/500 URLs | pages_ok=375 | chunks=3406\n",
      "Processed 400/500 URLs | pages_ok=400 | chunks=3557\n",
      "Processed 425/500 URLs | pages_ok=425 | chunks=3650\n",
      "Processed 450/500 URLs | pages_ok=450 | chunks=3748\n",
      "Processed 475/500 URLs | pages_ok=475 | chunks=3872\n",
      "Processed 500/500 URLs | pages_ok=500 | chunks=4004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'urls_seen': 500,\n",
       " 'pages_ok': 500,\n",
       " 'total_chunks': 4004,\n",
       " 'stats': {'pages_ok': 500},\n",
       " 'out': 'data/corpus_chunks.jsonl'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Corpus: 200 fixed + 300 random = 500 URLs. Extract, clean, and chunk the text (200-400 tokens with 50-token overlap). \n",
    "from src.build.build_corpus import build_corpus\n",
    "build_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ce374f5-b804-420c-a45c-2e89283ee896",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow<2.21,>=2.20 (from tf-keras)\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.33.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.73.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.6.15)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/331.9 MB 4.8 MB/s eta 0:01:09\n",
      "   ---------------------------------------- 1.8/331.9 MB 5.0 MB/s eta 0:01:06\n",
      "   ---------------------------------------- 3.1/331.9 MB 5.3 MB/s eta 0:01:03\n",
      "    --------------------------------------- 4.2/331.9 MB 5.1 MB/s eta 0:01:04\n",
      "    --------------------------------------- 5.2/331.9 MB 5.1 MB/s eta 0:01:05\n",
      "    --------------------------------------- 6.3/331.9 MB 5.1 MB/s eta 0:01:05\n",
      "    --------------------------------------- 7.3/331.9 MB 5.1 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.7/331.9 MB 5.1 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 9.7/331.9 MB 5.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 10.7/331.9 MB 5.2 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 11.8/331.9 MB 5.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 12.8/331.9 MB 5.0 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 13.9/331.9 MB 5.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 14.9/331.9 MB 5.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 16.0/331.9 MB 5.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 17.0/331.9 MB 5.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 18.1/331.9 MB 5.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 19.1/331.9 MB 5.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 20.2/331.9 MB 5.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 21.0/331.9 MB 5.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 22.0/331.9 MB 5.0 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 23.1/331.9 MB 5.0 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 23.9/331.9 MB 5.0 MB/s eta 0:01:02\n",
      "   --- ------------------------------------ 24.9/331.9 MB 5.0 MB/s eta 0:01:02\n",
      "   --- ------------------------------------ 26.2/331.9 MB 5.0 MB/s eta 0:01:02\n",
      "   --- ------------------------------------ 27.3/331.9 MB 5.0 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 28.6/331.9 MB 5.0 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 29.6/331.9 MB 5.1 MB/s eta 0:01:00\n",
      "   --- ------------------------------------ 30.9/331.9 MB 5.1 MB/s eta 0:01:00\n",
      "   --- ------------------------------------ 32.0/331.9 MB 5.1 MB/s eta 0:00:59\n",
      "   --- ------------------------------------ 33.0/331.9 MB 5.1 MB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 34.3/331.9 MB 5.1 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 35.7/331.9 MB 5.2 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 36.7/331.9 MB 5.2 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 38.0/331.9 MB 5.2 MB/s eta 0:00:57\n",
      "   ---- ----------------------------------- 39.3/331.9 MB 5.2 MB/s eta 0:00:57\n",
      "   ---- ----------------------------------- 40.4/331.9 MB 5.2 MB/s eta 0:00:56\n",
      "   ----- ---------------------------------- 41.7/331.9 MB 5.3 MB/s eta 0:00:56\n",
      "   ----- ---------------------------------- 43.0/331.9 MB 5.3 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 44.3/331.9 MB 5.3 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 45.4/331.9 MB 5.3 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 46.7/331.9 MB 5.3 MB/s eta 0:00:54\n",
      "   ----- ---------------------------------- 47.4/331.9 MB 5.3 MB/s eta 0:00:54\n",
      "   ----- ---------------------------------- 49.0/331.9 MB 5.3 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 50.3/331.9 MB 5.3 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 51.4/331.9 MB 5.3 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 52.7/331.9 MB 5.4 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 53.7/331.9 MB 5.3 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 55.1/331.9 MB 5.4 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 56.1/331.9 MB 5.4 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 57.1/331.9 MB 5.4 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 58.5/331.9 MB 5.4 MB/s eta 0:00:51\n",
      "   ------- -------------------------------- 59.8/331.9 MB 5.4 MB/s eta 0:00:51\n",
      "   ------- -------------------------------- 61.1/331.9 MB 5.4 MB/s eta 0:00:51\n",
      "   ------- -------------------------------- 62.4/331.9 MB 5.4 MB/s eta 0:00:50\n",
      "   ------- -------------------------------- 63.4/331.9 MB 5.4 MB/s eta 0:00:50\n",
      "   ------- -------------------------------- 64.7/331.9 MB 5.4 MB/s eta 0:00:50\n",
      "   ------- -------------------------------- 66.1/331.9 MB 5.4 MB/s eta 0:00:49\n",
      "   -------- ------------------------------- 67.1/331.9 MB 5.5 MB/s eta 0:00:49\n",
      "   -------- ------------------------------- 68.4/331.9 MB 5.5 MB/s eta 0:00:49\n",
      "   -------- ------------------------------- 69.7/331.9 MB 5.5 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 71.0/331.9 MB 5.5 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 72.4/331.9 MB 5.5 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 73.4/331.9 MB 5.5 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 74.4/331.9 MB 5.5 MB/s eta 0:00:47\n",
      "   --------- ------------------------------ 75.8/331.9 MB 5.5 MB/s eta 0:00:47\n",
      "   --------- ------------------------------ 77.1/331.9 MB 5.5 MB/s eta 0:00:47\n",
      "   --------- ------------------------------ 78.4/331.9 MB 5.5 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 79.4/331.9 MB 5.5 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 80.7/331.9 MB 5.5 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 81.8/331.9 MB 5.5 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 83.1/331.9 MB 5.5 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 84.4/331.9 MB 5.5 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 85.5/331.9 MB 5.5 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 86.8/331.9 MB 5.5 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 88.1/331.9 MB 5.6 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 89.4/331.9 MB 5.6 MB/s eta 0:00:44\n",
      "   ---------- ----------------------------- 90.7/331.9 MB 5.6 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 92.0/331.9 MB 5.6 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 93.3/331.9 MB 5.6 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 94.4/331.9 MB 5.6 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 95.7/331.9 MB 5.6 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 97.0/331.9 MB 5.6 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 98.3/331.9 MB 5.6 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 99.4/331.9 MB 5.6 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 100.9/331.9 MB 5.6 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 102.2/331.9 MB 5.6 MB/s eta 0:00:41\n",
      "   ------------ --------------------------- 103.5/331.9 MB 5.6 MB/s eta 0:00:41\n",
      "   ------------ --------------------------- 104.9/331.9 MB 5.6 MB/s eta 0:00:41\n",
      "   ------------ --------------------------- 106.4/331.9 MB 5.7 MB/s eta 0:00:40\n",
      "   ------------ --------------------------- 107.5/331.9 MB 5.7 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 108.5/331.9 MB 5.7 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 110.1/331.9 MB 5.7 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 111.7/331.9 MB 5.7 MB/s eta 0:00:39\n",
      "   ------------- -------------------------- 113.0/331.9 MB 5.7 MB/s eta 0:00:39\n",
      "   ------------- -------------------------- 114.3/331.9 MB 5.7 MB/s eta 0:00:39\n",
      "   ------------- -------------------------- 115.6/331.9 MB 5.7 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 117.2/331.9 MB 5.7 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 118.5/331.9 MB 5.7 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 120.1/331.9 MB 5.7 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 121.6/331.9 MB 5.8 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 122.9/331.9 MB 5.8 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 124.5/331.9 MB 5.8 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 126.1/331.9 MB 5.8 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 127.7/331.9 MB 5.8 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 129.0/331.9 MB 5.8 MB/s eta 0:00:35\n",
      "   --------------- ------------------------ 130.5/331.9 MB 5.8 MB/s eta 0:00:35\n",
      "   --------------- ------------------------ 131.9/331.9 MB 5.8 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 133.4/331.9 MB 5.8 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 135.0/331.9 MB 5.9 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 136.3/331.9 MB 5.9 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 137.6/331.9 MB 5.9 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 139.2/331.9 MB 5.9 MB/s eta 0:00:33\n",
      "   ---------------- ----------------------- 140.5/331.9 MB 5.9 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 141.8/331.9 MB 5.9 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 143.4/331.9 MB 5.9 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 144.7/331.9 MB 5.9 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 145.8/331.9 MB 5.9 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 147.3/331.9 MB 5.9 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 148.6/331.9 MB 5.9 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 149.9/331.9 MB 5.9 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 151.3/331.9 MB 5.9 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 152.6/331.9 MB 5.9 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 153.9/331.9 MB 5.9 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 155.2/331.9 MB 5.9 MB/s eta 0:00:30\n",
      "   ------------------ --------------------- 156.5/331.9 MB 5.9 MB/s eta 0:00:30\n",
      "   ------------------ --------------------- 157.5/331.9 MB 5.9 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 159.1/331.9 MB 5.9 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 160.4/331.9 MB 5.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 161.2/331.9 MB 5.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 162.5/331.9 MB 5.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 163.6/331.9 MB 5.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 164.9/331.9 MB 5.9 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 165.9/331.9 MB 5.9 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 167.2/331.9 MB 5.9 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 168.3/331.9 MB 5.9 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 169.6/331.9 MB 5.9 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 170.9/331.9 MB 5.9 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 172.2/331.9 MB 5.9 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 173.3/331.9 MB 5.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 174.9/331.9 MB 5.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 175.9/331.9 MB 5.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 177.2/331.9 MB 5.9 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 178.3/331.9 MB 5.9 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 179.8/331.9 MB 5.9 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 180.9/331.9 MB 5.9 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 182.5/331.9 MB 6.0 MB/s eta 0:00:26\n",
      "   ---------------------- ----------------- 183.5/331.9 MB 6.0 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 184.8/331.9 MB 6.0 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 186.1/331.9 MB 6.0 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 187.7/331.9 MB 6.0 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 189.0/331.9 MB 6.0 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 190.1/331.9 MB 6.0 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 191.6/331.9 MB 6.0 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 192.7/331.9 MB 6.0 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 194.0/331.9 MB 6.0 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 195.8/331.9 MB 6.0 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 197.1/331.9 MB 6.1 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 198.7/331.9 MB 6.1 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 200.0/331.9 MB 6.1 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 201.6/331.9 MB 6.1 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 202.9/331.9 MB 6.1 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 204.5/331.9 MB 6.1 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 206.0/331.9 MB 6.1 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 207.4/331.9 MB 6.2 MB/s eta 0:00:21\n",
      "   ------------------------- -------------- 208.7/331.9 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 210.0/331.9 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 211.3/331.9 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 212.9/331.9 MB 6.2 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 214.2/331.9 MB 6.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 215.7/331.9 MB 6.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 217.3/331.9 MB 6.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 218.9/331.9 MB 6.2 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 220.5/331.9 MB 6.3 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 222.0/331.9 MB 6.3 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 223.6/331.9 MB 6.3 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 225.2/331.9 MB 6.3 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 226.5/331.9 MB 6.3 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 228.1/331.9 MB 6.3 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 229.6/331.9 MB 6.3 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 230.9/331.9 MB 6.3 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 232.8/331.9 MB 6.3 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 234.4/331.9 MB 6.3 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 235.7/331.9 MB 6.4 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 237.2/331.9 MB 6.4 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 238.8/331.9 MB 6.4 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 239.9/331.9 MB 6.4 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 241.2/331.9 MB 6.4 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 242.5/331.9 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 244.1/331.9 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 245.4/331.9 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 246.9/331.9 MB 6.4 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 248.5/331.9 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 250.1/331.9 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 251.7/331.9 MB 6.5 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 253.2/331.9 MB 6.5 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 254.8/331.9 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 256.1/331.9 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 257.4/331.9 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 259.0/331.9 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 260.0/331.9 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 261.4/331.9 MB 6.5 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 262.7/331.9 MB 6.5 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 264.2/331.9 MB 6.5 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 265.6/331.9 MB 6.5 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 266.9/331.9 MB 6.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 268.2/331.9 MB 6.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 269.7/331.9 MB 6.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 271.1/331.9 MB 6.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 272.6/331.9 MB 6.5 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 273.2/331.9 MB 6.5 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 273.9/331.9 MB 6.5 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 275.5/331.9 MB 6.5 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 277.1/331.9 MB 6.5 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 278.9/331.9 MB 6.5 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 280.2/331.9 MB 6.5 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 281.5/331.9 MB 6.5 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 283.4/331.9 MB 6.6 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 284.7/331.9 MB 6.6 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 286.3/331.9 MB 6.6 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 287.8/331.9 MB 6.6 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 289.4/331.9 MB 6.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 290.7/331.9 MB 6.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 292.3/331.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 293.6/331.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 294.9/331.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 296.2/331.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 297.5/331.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 298.8/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 299.9/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 301.2/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 302.3/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 303.6/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 304.6/331.9 MB 6.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 305.7/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 307.0/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 308.0/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 309.3/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 310.6/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 312.0/331.9 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 313.3/331.9 MB 6.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 314.3/331.9 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 315.6/331.9 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 316.9/331.9 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 318.0/331.9 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 319.3/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 320.6/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 321.7/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 323.0/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  324.3/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  325.3/331.9 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  326.6/331.9 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  327.9/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  329.0/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.3/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.6/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/331.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.9/331.9 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.5 MB 7.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 5.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard, tensorflow, tf-keras\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.19.0\n",
      "    Uninstalling tensorboard-2.19.0:\n",
      "      Successfully uninstalled tensorboard-2.19.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.19.0\n",
      "    Uninstalling tensorflow-2.19.0:\n",
      "      Successfully uninstalled tensorflow-2.19.0\n",
      "Successfully installed tensorboard-2.20.0 tensorflow-2.20.0 tf-keras-2.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\stanh\\anaconda3\\Lib\\site-packages\\~ensorflow'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "704898ac-d9e8-4021-8b7f-46345df5a622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\stanh\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'collection': 'wiki_chunks_dense',\n",
       " 'persist_dir': 'indexes/chroma',\n",
       " 'num_chunks_indexed': 4004,\n",
       " 'embedding_model': 'all-MiniLM-L6-v2'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store with metadata (URL, title, unique chunk IDs).\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.index.dense_chroma import build_dense_index\n",
    "build_dense_index(corpus_path=\"data/corpus_chunks.jsonl\",\n",
    "                  embedding_model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3067e3e9-e5d0-4c5f-b1eb-3fe29ffd54be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4004\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient(path=\"indexes/chroma\")\n",
    "col = client.get_collection(\"wiki_chunks_dense\")\n",
    "print(col.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e9bc5-7a0b-4d87-ac59-4ba84f3f35dc",
   "metadata": {},
   "source": [
    "<h1> Part 1: Hybrid RAG System (10 Marks) </h1>\n",
    "<h2>1.1 Dense Vector Retrieval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d12f04bc-4a10-46fc-ab93-b992ffadce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6111284494400024 Mathematics https://en.wikipedia.org/wiki/Mathematics\n",
      "2 0.4509149193763733 Mathematics https://en.wikipedia.org/wiki/Mathematics\n",
      "3 0.4466514587402344 Mathematics https://en.wikipedia.org/wiki/Mathematics\n",
      "4 0.4119247794151306 Mathematics https://en.wikipedia.org/wiki/Mathematics\n",
      "5 0.4009022116661072 Computer science https://en.wikipedia.org/wiki/Computer_science\n"
     ]
    }
   ],
   "source": [
    "from src.index.dense_chroma import dense_retrieve\n",
    "\n",
    "results = dense_retrieve(\"Who developed the theory of relativity?\", top_k=5)\n",
    "for r in results:\n",
    "    print(r[\"dense_rank\"], r[\"dense_score\"], r[\"title\"], r[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc235c8-febd-47e3-99cd-fcc1381a3371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\stanh\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from rank-bm25) (1.26.4)\n",
      "Requirement already satisfied: click in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\stanh\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install rank-bm25 nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b55b20-d48b-46e1-9bcd-9263319c6957",
   "metadata": {},
   "source": [
    "<h2>1.2 Sparse Keyword Retrieval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08b1bcbb-de00-46ef-81ae-9d1499dd3fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bm25_docs_indexed': 4004,\n",
       " 'bm25_path': 'indexes\\\\bm25.pkl',\n",
       " 'meta_path': 'indexes\\\\bm25_meta.pkl'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.index.sparse_bm25 import build_bm25_index\n",
    "build_bm25_index(\"data/corpus_chunks.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "784453cd-61e4-4b7b-a6bf-bd094de1cd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 25.665557146120218 Mathematics https://en.wikipedia.org/wiki/Mathematics\n",
      "2 19.400331320468716 Shockwave cosmology https://en.wikipedia.org/wiki/Shockwave_cosmology\n",
      "3 17.535417988947067 Outline of astronomy https://en.wikipedia.org/wiki/Outline_of_astronomy\n",
      "4 17.3757136111653 Outline of astronomy https://en.wikipedia.org/wiki/Outline_of_astronomy\n",
      "5 16.88574616717827 Mathematics https://en.wikipedia.org/wiki/Mathematics\n"
     ]
    }
   ],
   "source": [
    "from src.index.sparse_bm25 import sparse_retrieve\n",
    "\n",
    "res = sparse_retrieve(\"Who developed the theory of relativity?\", top_k=5)\n",
    "for r in res:\n",
    "    print(r[\"bm25_rank\"], r[\"bm25_score\"], r[\"title\"], r[\"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca91f445-cfc6-45e9-9c37-1d36f8e9f62f",
   "metadata": {},
   "source": [
    "<h2>1.3 Reciprocal Rank Fusion (RRF)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab610087-d19e-487c-97ae-700e98ffb2b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query =\"Wayland Balloon Fest ?\"\n",
    "\n",
    "dense_results = dense_retrieve(query, top_k=30)\n",
    "sparse_results = sparse_retrieve(query, top_k=30)\n",
    "\n",
    "from src.rag.rrf import rrf_fusion\n",
    "\n",
    "final_context_chunks = rrf_fusion(\n",
    "    dense_results,\n",
    "    sparse_results,\n",
    "    k=60,\n",
    "    top_n=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e8443b9-bf4c-4696-b96b-80a44c369645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Context 1\n",
      "URL: https://en.wikipedia.org/wiki/Fort_Nelson,_British_Columbia\n",
      "RRF score: 0.031545\n",
      "--------------------------------------------------------------------------------\n",
      "the Northern Lights festival struggled to attract any tourists into the region in 2020. == Attractions == In Fort Nelson Fort Nelson Heritage Museum Poplar Hills Golf Club The Phoenix Theatre Northern Rockies Recreation Centre Fort Nelson Community Literacy Society's October Culture Fest The Northern Lights Festival including: Canadian Open Dog Sled Races Dene Handgames Northern Lights Trappers Rendezvous Trade Show (May) Canoeing down the Fort Nelson River In the Northern Rockies Liard Hot Springs Northern Rocky Mountains Provincial Park Smith River Falls – Fort Halkett Provincial Park Wokkpash Lake and the Wokkpash Recreation Area Muncho Lake (of blue-green color, due to glacial flour) Rafting on the Liard River On 18 June 2005, people in Fort Nelson held a water balloon fight with over 40,000 water balloons being tossed in less than three minutes. At the time, it was a world record. == Government == Fort Nelson was originally incorporated as a village in 1971, but established itself as an unregistered community shortly before that. In 1960, based on significant growth in the oil and gas industry of the region, the Fort Nelson Improvement District was formed in order to provide community members with essential infrastructural needs such as water and sewer services. Harry Clarke was elected the first mayor of Fort Nelson in 1971 and since then, Fort Nelson has consistently\n",
      "\n",
      "📄 Context 2\n",
      "URL: https://en.wikipedia.org/wiki/Coachella_Festival_line-ups\n",
      "RRF score: 0.031258\n",
      "--------------------------------------------------------------------------------\n",
      "Long March, Punch, Nidhogg, The Do Lab, The Do Lab's Pagoda, Winwin Creative: Joy, Michael Christian: Candelaphytes, Hotshot the Robot, Cyclecide Bike Rodeo, reel-Mobile, Coachella Art Studios, Rob Buchholz: Wish, Todd Williams: Land Sharks, Syd Klinge: (CauacTwins), Christian Ristow: Fledgling, Balloon Chain, A Physical Manifestation of Ladies and Gentlemen We Are Floating in Space: Jonathan Glazer + J. Spaceman with Undisclosable and One of Us. === 2012 === ==== Friday, April 13 & 20 ==== The Do LaB Weekend 1: Lucent Dossier Experience, Stephan Jacobs, Sugarpill, Jupit3r, Gladkill, Russ Liquid, GoldRush, CrisB., Jobot, Patricio The Do LaB Weekend 2: Lucent Dossier Experience, Jupit3r, Patricio, Jeremy Sole, Marley Carroll, Geno Cochino, Natasha Kmeto, Quade Heineken Dome Weekend 1: EC Twins, Andy Caldwell, Hot Mouth, Zen Freeman, La' Reda Heineken Dome\n",
      "\n",
      "📄 Context 3\n",
      "URL: https://en.wikipedia.org/wiki/Coachella_Festival_line-ups\n",
      "RRF score: 0.02967\n",
      "--------------------------------------------------------------------------------\n",
      "ill, Dimond Saints, Slow Magic, ill-esha, Chrime Sparks, El Papa Chango, Two Fresh, Vokab Kompany & Crush Effect, Dessert Dwellers The Do LaB Weekend 2: Mitis, Opiuo, Freddy Todd, Jupit3r, Love & Light, Chris B, Hunterleggit, Hopscotch, Ruff Hauser Heineken House Weekend 1: Last Call, Flight Facilities, Chela, MDNR, Femme, Sean Glass x Goddollars Heineken House Weekend 2: Classixx (DJ), Escort with MNDR, Surprise Guest, Flight Facilities, Preservation Hall Jazz Band, Surprise Guest, MDNR, Femme, Sean Glass Dropped Acts: Beady Eye In 2014, art contributions included: 2Squared by Charles Gadeken; Balloon Chain by Robert Bose; Becoming Human by Christian Ristow; Cryochome by James Peterson; The Do Lab by Eepert Village; Escape Velocity (The Astronaut) by Poetic Kinetics; Smartbird by Festo; Giant Green Caterpillar by Mike Grandaw; Lightweaver by Stereo-Bot; Lucent Dossier Experience; Reflection Field by Philip K. Smith III; Archetypes by Keith Greco; Arche\n",
      "\n",
      "📄 Context 4\n",
      "URL: https://en.wikipedia.org/wiki/Coachella_Festival_line-ups\n",
      "RRF score: 0.028324\n",
      "--------------------------------------------------------------------------------\n",
      "Coachella Art Studios, Charles Gadeken: (WAVE), Todd Williams: (Land Shark), Gerard Minakawa: (Starry Bamboo), Hotshot the Robot, Susan Robb: (Warmth, Giant Black Tubes), Christian Ristow: (Garaplata), Shrine: (Shacks), Robert Bose: (Balloon Chain), Sensory Sync: (Gateway), Poetic Kinetic: (Solitary Inflorescence), Cyclecide and Makeover Mechanix. === 2013 === ==== Friday, April 12 & 19 ==== The Do LaB Weekend 1: Goldrush, Lucent Dossier Experience, Run DMT, R/D, Robotic Pirate Monkey, Unlimited Gravity, G Jones, Manic Focus, Jupit3r, Hunterleggitt The Do LaB Weekend 2: Kastle, Lucent Dossier Experience, Kraddy, Jupit3r, Stephan Jacobs, Sugarpill, Metaphase, Astronautica Heineken Dome Weekend 1: Kenny \"Dope\" Gonzalez, DJ Spen, Acid Face, Sex Panther, David Paul Heineken Dome Weekend 2: Gene Farris, Sonny Fodera, J. Phlip, Ale Rauen (b2b) Rodrigo Vieira\n",
      "\n",
      "📄 Context 5\n",
      "URL: https://en.wikipedia.org/wiki/Coachella_Festival_line-ups\n",
      "RRF score: 0.027052\n",
      "--------------------------------------------------------------------------------\n",
      "e Beretta Dropped Acts: Kele, Dubfire In 2015, art contributions included: Papilio Merraculous by Poetic Kinetics; Do LaB by Big Fish; Balloon Chain by Robert Bose; Party God by the Haas Brothers; Big Bear by Don Kennell; Praxis by Ben Zamora and John Zamora; Pulp Pavilion by Ball-Nogues Studio; the Corporate Headquarters by Derek Doublin and Vanessa Bonet; Earthmover by Christian Ristow; the Jive Joint by Super Tall Paul & Rossome; Big Horn Place by Shrine & Joel Dean Stockdill; Pulp Pavilion by Ball-Nogues Studio; Coachella Bound by Raices Cultura; Twelve Shades of Pass.ani by Keith Greco; Lighthouse by Randy Polumbo; Chrono Chromatic by Aphidoidea; and Coachella Art Studios. === 2016 === ==== Friday, April 15 & 22 ==== The Do LaB Weekend 1: What So Not, Speaker of the House, KRNE, Ghastly, Wave Racer, Stylust Beats, JayKode, Everyman, Dreamers Delight, Mountain of Youth The Do LaB Weekend 2: Hippie Sabotage, Sweater Beats, Stwo, Sam Gellait\n",
      "\n",
      "📄 Context 6\n",
      "URL: https://en.wikipedia.org/wiki/Denizen_(film)\n",
      "RRF score: 0.026786\n",
      "--------------------------------------------------------------------------------\n",
      "fest of horror coming our way. (In case you didn’t know, fromage means “cheese” in French)\", offering \"at the very least, it could make for some check-your-brain-at-the-door fun\", and summarized by writing \"there is an abundance of hot ladies in the cast, including a special appearance by none other than horror’s #1 vixen, Tiffany Shepis.\" Nic Brown of B Movie Man wrote that [the film] \"is a mix of action, horror and science fiction. It has plenty of gun play and a surprising array of stunts including deep water scuba shoots, sky diving, and some military fighter action,\" with \"an array of interesting characters,\" and concluded that it was \"a respectable independent action film with elements of sci-fi and horror thrown in.\" Nic Baisley of Film Snobbery wrote \"The fairly wide variety of locations used in the movie also add that sense of realism to the story that is generally left out in some films. The use of multiple locations adds a lot of free production value to an otherwise obviously low-budget film. Other things in this film that should be given kudos are the action scenes, underwater filmed scenes, and even an unexpected aerial skydiving scene. J.A. Steel definitely knew how to take advantage of her limited budget on this\n",
      "\n",
      "📄 Context 7\n",
      "URL: https://en.wikipedia.org/wiki/Universities_of_Glasgow_and_Strathclyde_Air_Squadron\n",
      "RRF score: 0.026263\n",
      "--------------------------------------------------------------------------------\n",
      "nd Tiger Moth T.2 (1946–1950) Miles Magister (1946–1950) De Havilland Chipmunk T.10 (1950–1974) Scottish Aviation Bulldog T.1 (1974–2000) Grob 115E Tutor T.1 (2000–2010) Grob 115EA Tutor T.2 (2010 – present) == Incidents == 9 July 1951, at Creampoke Woods at Stainfield, Lincolnshire, 'WD360' crashed, with JK McIntyre killed 11 December 2002, a Grob Tutor crashed into a field in Gartocharn, near Loch Lomond, after engine failure. Both the student pilot and instructor managed to walk away from the crash unharmed. 4 November 2022, a Grob Tutor operated by the air squadron declared pan-pan and squawked 7700 over Glasgow after experiencing low oil pressure and low RPM with the aircraft's engine. The aircraft returned safely to Glasgow airport with both crew members unharmed. == Alumni == Don Cameron (balloonist), built Britain's first hot air balloon in 1967, the Bristol Belle ==\n",
      "\n",
      "📄 Context 8\n",
      "URL: https://en.wikipedia.org/wiki/Coachella_Festival_line-ups\n",
      "RRF score: 0.016393\n",
      "--------------------------------------------------------------------------------\n",
      ", Sweet Like Chocolate Heineken House Weekend 2: Franc Moody (DJ Set), SG Lewis (DJ Set), TEED b2b SG Lewis, Totally Enormous Extinct Dinosaurs (DJ Set), Coco & Breezy, Zen Freeman ==== Sunday, April 16 & 23 ==== The Do LaB Weekend 1: Dombresky presents Disco Dom, Kasablanca, Franky Wah, Dylan & Harry (Party Favor & Baauer), Daily Bread, Aluna, Elif, Henry Pope, Miss Javi The Do LaB Weekend 2: DRAMA, Gioli & Assia, DEVAULT, ODD MOB, ARODES, Hank K, SYREETA, Carré b2b Samwise Heineken House Weekend 1: LondonBridge, NGHTMRE, Whipped Cream, Niiko x Swae, Tony H Heineken House Weekend 2: Snakehips, Fleetmac Wood, Bontan, Black V Neck, Max Styler Plus: DESPACIO playing all weekend long Dropped acts: 1999.ODDS === 2024 === The 2024 festival was organized from April 12–14 and 19–21 featuring Lana Del Rey, Tyler, the Creator, Doja Cat and No\n",
      "\n",
      "📄 Context 9\n",
      "URL: https://en.wikipedia.org/wiki/Coachella_Festival_line-ups\n",
      "RRF score: 0.016129\n",
      "--------------------------------------------------------------------------------\n",
      "Count Bass D, Ife Radio, Junie., Harlie, Tsugu ==== Sunday, April 17 & 24 ==== The Do LaB Weekend 1: Dom Dolla b2b John Summit, Off The Deep End, CID, Totally Enormous Extinct Dinosaurs (DJ Set), Chloé Caillet, QRTR, Balkan Bump, Duskus The Do LaB Weekend 2: DJ Hanzel, Elohim (DJ Set), Justin Martin, Vintage Culture, LP Giobbi, Yulia Niko, Patricio, Hunter Leggitt Heineken House Weekend 1: Ms Nina (DJ Set), D33J, Mia Carucci, Donovan's Sound Club, Bitter Babe, PIERI, Mueka, Mawingo, TRYi Heineken House Weekend 2: Major League Djz, Silent Addy, Bitter Babe, Surprise Guest, PIERI, Brava, Mueka, Mawingo, TRYi Dropped acts: Ye, Satori === 2023 === The 2023 festival was organized from April 14–16 and 21–23 and featured Bad Bunny, Blackpink, Frank Ocean and Calvin Harris as the headlining acts.\n",
      "\n",
      "📄 Context 10\n",
      "URL: https://en.wikipedia.org/wiki/Coachella_Festival_line-ups\n",
      "RRF score: 0.015873\n",
      "--------------------------------------------------------------------------------\n",
      ": Ye, Satori === 2023 === The 2023 festival was organized from April 14–16 and 21–23 and featured Bad Bunny, Blackpink, Frank Ocean and Calvin Harris as the headlining acts. ==== Friday, April 14 & 21 ==== The Do LaB Weekend 1: Vintage Culture b2b Mochakk, Flight Facilities (DJ Set), James Blake presents CMYK, Whipped Cream, The Glitch Mob, Mr. Carmack, BAMBII, Michal Brun, Andreas One The Do LaB Weekend 2: The Brothers Macklovitch (A-Trak & Dave1), Knock2, Disco Wrek (Disco Lines b2b Ship Wrek), Of The Trees, The Funk Hunters, Maddy O'Neal, Flamingosis, Emmit Fenn, Patricio, Ali Farahani b2b Patrik Khach, Littlefoot Heineken House Weekend 1: Felix da Housecat, Walker & Royce, Hannah Wants, Lee Wells, BONES Heineken House Weekend 2: Emmit Fenn, Chris Stussy, Francis Mercier, HoneyLuv, Antoinette Van Dewark ==== Saturday, April 15 &\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(final_context_chunks, start=1):\n",
    "    print(f\"\\n📄 Context {i}\")\n",
    "    print(\"URL:\", c.get(\"url\"))\n",
    "    print(\"RRF score:\", round(c[\"rrf_score\"], 6))\n",
    "    print(\"-\"*80)\n",
    "    print(c[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0363c-b3a1-4fc6-8d2f-0ba0a912200e",
   "metadata": {},
   "source": [
    "<h2>1.4 Response Generation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3256d11f-15cc-4df5-bc9f-2843f3eae5a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Note: Activate Environment & Install Libraries (one-time)\n",
    "#!pip install transformers sentencepiece torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "933ac88e-8cc1-4b84-81fc-4fe6f26ce9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Paths in the directory\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30ebe7c9-1974-47db-8257-dfe6fa80a408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1) The Air Balloon, Birdlip | https://en.wikipedia.org/wiki/The_Air_Balloon,_Birdlip | RRF=0.03252\n",
      "The Air Balloon is a road junction and former pub in Birdlip, Gloucestershire, England. The junction is on the A417 at a significant congestion point. The pub was open from the late 18th century to 2022, when it closed as part of road improvements, a\n",
      "\n",
      "2) Calkins Field | https://en.wikipedia.org/wiki/Calkins_Field | RRF=0.03252\n",
      "Calkins Field (FAA LID: 41C) is a privately owned, public use airport located 1 mile north of Wayland, Michigan. The airport sits on 105 acres at an elevation of 740 feet. The airport is named for the Calkins Family, which has lived in the Wayland ar\n",
      "\n",
      "3) The Air Balloon, Birdlip | https://en.wikipedia.org/wiki/The_Air_Balloon,_Birdlip | RRF=0.02967\n",
      "the Air Balloon in 1802. By 1856, the landlord was brewing beer on-site. The premises were part of the Cowley Manor estate until some time early in the 20th century. The pub was bought by Greene King in 2004. In 2020 the menu included burgers, steaks\n",
      "\n",
      "4) Yonder Mountain String Band | https://en.wikipedia.org/wiki/Yonder_Mountain_String_Band | RRF=0.02921\n",
      "was to open for a band at the Fox Theatre in Boulder. The band developed both a bluegrass and jam band fan base, and can often be found on tour. Their debut album Elevation was released on Frog Pad Records, an independent record label run by the band\n",
      "\n",
      "5) The Air Balloon, Birdlip | https://en.wikipedia.org/wiki/The_Air_Balloon,_Birdlip | RRF=0.02844\n",
      "Highways England stated that it would consult landowners and assess the social impact of the pub's demolition in a further design stage. As of June 2021, the pub was open, but was expected to be demolished. The landlord subsequently announced in Dece\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(final_context_chunks[:5], start=1):\n",
    "    print(f\"\\n{i}) {c.get('title')} | {c.get('url')} | RRF={c['rrf_score']:.5f}\")\n",
    "    print(c[\"text\"][:250].replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7856e770-2151-4821-98d8-f13b45f3e00d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use ONLY the context to answer the question.\n",
      "If the answer is not present in the context, reply exactly: Not available in context.\n",
      "\n",
      "Provide a complete and concise answer ending with a full stop.\n",
      "\n",
      "Context:\n",
      "The Air Balloon is a road junction and former pub in Birdlip, Gloucestershire, England. The junction is on the A417 at a significant congestion point. The pub was open from the late 18th century to 2022, when it closed as part of road improvements, and was subsequently demolished. == Location == The pub stood next to a roundabout junction on the A417, a major road between Swindon and Gloucester via Cirencester. The A436 meets the A417 at this point; the two roads together form a de facto bypass of Cheltenham between Oxford and Gloucester. == History == The pub opened in 1784 and was probably named after one of the first British balloon flights: the launching of a small hydrogen balloon by Ed\n",
      "\n",
      "---\n",
      "\n",
      "Calkins Field (FAA LID: 41C) is a privately owned, public use airport located 1 mile north of Wayland, Michigan. The airport sits on 105 acres at an elevation of 740 feet. The airport is named for the Calkins Family, which has lived in the Wayland area for generations. The airport is located on their property. == Facilities and aircraft == The airport has two runways, both made of turf. Runway 1/19 measures 2200 x 75 ft (671 x 23 m), and runway 9/27 measures 1800 x 100 ft (549 x 30 m). For the 12-month period ending December 31, 2015, the airport had 1508 aircraft operations, an average of 29 per week. It was all general aviation. For the same time period, 10 aircraft are based at the airpor\n",
      "\n",
      "---\n",
      "\n",
      "the Air Balloon in 1802. By 1856, the landlord was brewing beer on-site. The premises were part of the Cowley Manor estate until some time early in the 20th century. The pub was bought by Greene King in 2004. In 2020 the menu included burgers, steaks, vegetarian food, \"pub classics\" and a lunchtime carvery. == Closure == The pub was under threat of demolition as it sat alongside a short section of single-carriageway road which is otherwise a high-quality route between the M4 and M5 motorways. Although the junction has been said to be a notorious accident blackspot, from 1999 to 2014 there were an estimated 340 casualties along the whole section of road, which National Highways said was below\n",
      "\n",
      "---\n",
      "\n",
      "was to open for a band at the Fox Theatre in Boulder. The band developed both a bluegrass and jam band fan base, and can often be found on tour. Their debut album Elevation was released on Frog Pad Records, an independent record label run by the band, in the fall of 1999. From 1999 to 2001 they performed as one of the many attractions at NedFest, a music festival held in the band's hometown. By 2000, the group was also playing larger venues, such as The Fillmore in San Francisco, California. In 2005, their recording of \"Think for Yourself\" was included on the album This Bird Has Flown – A 40th Anniversary Tribute to the Beatles' Rubber Soul. In 2008, the band performed at the 2008 Democratic\n",
      "\n",
      "---\n",
      "\n",
      "Highways England stated that it would consult landowners and assess the social impact of the pub's demolition in a further design stage. As of June 2021, the pub was open, but was expected to be demolished. The landlord subsequently announced in December 2022 that the pub would close on New Year's Eve, and then it would be demolished. Actor John Challis' widow said the couple used to visit the pub regularly, and she was sad to see it close. A spokesperson for Highways England expressed surprise at the pub's closure, saying it could have stayed open longer. There were additional concerns that a now-closed prominent landmark could become a magnet for vandalism. The premises were demolished in \n",
      "\n",
      "---\n",
      "\n",
      "=== Plug in city. Archigram, 1962–1966 === A megastructure that had no buildings, just a large frame into which housing or service capsules could be fitted in the form of cells or standardized components. Each element had a durability; the base structure contained only about 50% of its weight - so if you're looking for something more modern than your old home building look elsewhere! If we don't know what type of material will fit inside our house please let us KNOW!!\n"
     ]
    }
   ],
   "source": [
    "# distilgpt2\n",
    "\n",
    "# from src.rag.generate import generate_answer_distilgpt2\n",
    "# contexts = [c[\"text\"] for c in final_context_chunks]   # top-N from RRF\n",
    "# answer = generate_answer_distilgpt2(query, contexts)\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2882cdd3-4249-4364-bde8-7887d34d47b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " The Do LaB Weekend 2: Mitis, Opiuo, Freddy Todd, Jupit3r, Love & Light, Chris B, Hunterleggit, Hopscotch, Ruff Hauser Heineken House Weekend 1: What So Not, Speaker of the House, KRNE, Ghast --- fest of horror coming our way. (In case you didn’t know, fromage means “cheese” in French)\", offering \"at the very least, it could make for some check-your-brain-at-the-door fun\", and summarized by writing \"there is an abundance of hot ladies in the cast, including a special appearance by none other than horror’s #1 vixen, Tiffany Shepis.\n",
      "\n",
      "Debug: {'model': 'google/flan-t5-large', 'prompt_tokens': 2536, 'max_input_tokens': 2536, 'max_new_tokens': 220}\n"
     ]
    }
   ],
   "source": [
    "#Generate answers within context limits.\n",
    "from src.rag.generate_flan_t5 import generate_answer_flan_t5\n",
    "\n",
    "contexts = [c[\"text\"] for c in final_context_chunks]   # top-N from RRF\n",
    "\n",
    "answer, debug = generate_answer_flan_t5(\n",
    "    query,\n",
    "    contexts,\n",
    "    max_input_tokens=2536,\n",
    "    max_new_tokens=220\n",
    ")\n",
    "\n",
    "print(\"Answer:\\n\", answer)\n",
    "print(\"\\nDebug:\", debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d80635d9-14d8-440b-9618-5216fb86db80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "football is quite unsuitable for females and should not be encouraged\". Players and football writers have argued that this ban was, in fact, due to envy of the large crowds that women's matches attracted. The FA ban led to the formation of the short-lived English Ladies Football Association and play moved to rugby grounds.\n",
      "Time: 46.745\n",
      "Outline of association football 0.03252247488101534\n",
      "Outline of association football 0.0315136476426799\n",
      "Names for association football 0.03057889822595705\n"
     ]
    }
   ],
   "source": [
    "#Pipeline Testing\n",
    "from src.rag.pipeline import run_rag_pipeline\n",
    "\n",
    "out = run_rag_pipeline(\"Association football history\")\n",
    "\n",
    "print(out[\"answer\"])\n",
    "print(\"Time:\", out[\"response_time\"])\n",
    "\n",
    "for c in out[\"contexts\"][:3]:\n",
    "    print(c[\"title\"], c[\"rrf_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6722f-0268-4bf7-a703-10985711b273",
   "metadata": {},
   "source": [
    "<h2> 1.5 User Interface </h2>\n",
    "<h3> Build with Streamlit/Gradio/Flask. Display: user query input, generated answer, top retrieved chunks with sources, dense/sparse/RRF scores, and response time.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eaa800-e134-4a2e-829d-3beb7ce6d832",
   "metadata": {},
   "source": [
    "Please Follow the following steps to run the streamlit\n",
    "\n",
    "1. Activate Environment & Install Libraries (one-time)\n",
    "2. Run Streamlit App in the terminal <i> streamlit run streamlit_app.py </i>\n",
    "3. A browser window will automatically open at: http://localhost:8501\n",
    "\n",
    "\n",
    "<b> Note </b>\n",
    "\n",
    "1. App runs from project root\n",
    "2. Uses existing indexes/ and data/ folders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e158e-e095-4247-b4ef-f1dd1519d071",
   "metadata": {},
   "source": [
    "<h1>Part 2: Automated Evaluation (6 + 4 Marks)</h1>\n",
    "<h2>2.1 Question Generation (Automated)</h2>\n",
    "\n",
    "\n",
    "Generate 100 Q&A pairs from Wikipedia corpus using LLMs or extraction methods. Include diverse question types: factual, comparative, inferential, multi-hop. Store with ground truth, source IDs, and question categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be796465-9d90-4974-9b73-5e194fe151cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 100, 'out': 'data/questions_100.jsonl'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics.generate_questions import generate_questions\n",
    "res = generate_questions(\n",
    "    corpus_jsonl=\"data/corpus_chunks.jsonl\",\n",
    "    out_jsonl=\"data/questions_100.jsonl\",\n",
    "    seed=7\n",
    ")\n",
    "\n",
    "## Sample\n",
    "# qid \"q0004\"\n",
    "# question \"What is Guaiacol?\"\n",
    "# answer \"Guaiacol () is an organic compound with the formula C6H4(OH)(OCH3).\" -- Ground Truth\n",
    "# category \"factual\" --0 Question Category\n",
    "##\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e9d52-5a2c-41b3-ac27-ba42b9a37310",
   "metadata": {},
   "source": [
    "<h2>2.2 Evaluation Metrics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dadcc25-72be-47a3-84ab-759dbdcf5d73",
   "metadata": {},
   "source": [
    "<h2>2.2.1 Mandatory Metric (Basic - 2 Marks)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eff012-0e33-4f92-bbf0-9c54ca244ec8",
   "metadata": {},
   "source": [
    "Mean Reciprocal Rank (MRR) - URL Level: Calculate MRR at the URL level (not chunk level). For each question, find the rank position of the first correct Wikipedia URL in the retrieved results. MRR = average of 1/rank across all questions. This measures how quickly the system identifies the correct source document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5a99dcf-2aa4-464c-abae-0e42eda12d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.index.dense_chroma import dense_retrieve\n",
    "# from src.index.sparse_bm25 import sparse_retrieve\n",
    "# from src.rag.rrf import rrf_fusion\n",
    "\n",
    "# def retrieval_only(query: str, top_k_dense=50, top_k_sparse=50, top_n_context=50, rrf_k=60):\n",
    "#     dense = dense_retrieve(query, top_k=top_k_dense)\n",
    "#     sparse = sparse_retrieve(query, top_k=top_k_sparse)\n",
    "#     fused = rrf_fusion(dense, sparse, k=rrf_k, top_n=top_n_context)\n",
    "#     return fused"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce784b3-7444-40f7-b28f-5038d17e9c0f",
   "metadata": {},
   "source": [
    "<h2>NOTE:</h2>\n",
    "<h3> MRR is calculated in 2.2.2 along with Additional Custom Metrics </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d2e49-534e-49f0-a23b-d1ae65606c6b",
   "metadata": {},
   "source": [
    "<h2>2.2.2 Additional Custom Metrics (4 Marks)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d69c79da-6528-4843-ae7d-d2ea61df60f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.9162\n",
      "Precision@5: 0.224\n",
      "Faithfulness: 0.9924\n"
     ]
    }
   ],
   "source": [
    "from src.metrics.run_custom_metrics import run_custom_metrics\n",
    "run_custom_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4b25e-2eda-4b9d-884a-244cff91dc5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h3> URL-level MRR: 0.9</h3>\n",
    "An MRR of 0.9 indicates that the correct source URL is retrieved at the top rank for the majority of questions, demonstrating strong retrieval effectiveness of the hybrid RAG system.\n",
    "\n",
    "<h3>Metric 1: Precision@5</h3>\n",
    "\n",
    "Why this metric is important\n",
    "\n",
    "Precision@5 measures how many of the top 5 retrieved documents are actually relevant to the query. This metric is important because in a RAG system, the language model only sees a limited number of retrieved documents (usually top-K). If these documents are not relevant, the model may generate incorrect or incomplete answers.\n",
    "\n",
    "Precision@5 helps answer a very practical question:\n",
    "\n",
    "“When my system retrieves 5 documents, how many of them are truly useful?”\n",
    "\n",
    "So, this metric directly evaluates retrieval quality, which is the foundation of any RAG pipeline.\n",
    "\n",
    "\n",
    "\n",
    "<h2>Mathematical formulation</h2>\n",
    "\n",
    "For a given query:\n",
    "\n",
    "Precision@5= (Number of relevant documents in top 5) / 5\n",
    "\t\n",
    "If we evaluate over 𝑁 queries, the final score is the average:\n",
    "\n",
    "Precision@5=  Summation (From 1 - N) of Precision@5(Qi) / N\n",
    "\n",
    "\n",
    "<h2>How it was calculated (implementation logic)</h2>\n",
    "\n",
    "For each query, the retriever returns the top 5 documents. Each document is checked against ground truth to see if it is relevant. The number of relevant documents in the top 5 is counted. This count is divided by 5. The score is averaged across all queries.\n",
    "\n",
    "<h3>Interpretation of my result</h3>\n",
    "\n",
    "<h4>Precision@5 = 0.2, This means that on average, only 1 out of the top 5 retrieved documents is relevant.</h4>\n",
    "\n",
    "The retriever is able to find the correct document sometimes, but most of the retrieved context contains irrelevant or noisy information, this can increase prompt length and reduce answer clarity\n",
    "\n",
    "<h3>Benefit of this metric:</h3>\n",
    "It clearly shows that retrieval needs improvement (better embeddings, chunking, filters, or reranking), even if generation looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82547a68-3c6f-4e0d-882d-a1bc9d9983d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> Metric 2: Faithfulness</h2>\n",
    "<h3> Why this metric is important </h3>\n",
    "\n",
    "Faithfulness measures whether the generated answer is supported by the retrieved documents.\n",
    "Even with RAG, language models can hallucinate or add extra information not present in the context.\n",
    "\n",
    "This metric answers:\n",
    "\n",
    "“Is the model answering only from the provided documents, or inventing facts?”\n",
    "\n",
    "Faithfulness is extremely important for trustworthy AI systems, especially in domains like education, healthcare, or enterprise search.\n",
    "\n",
    "<h3>Mathematical formulation</h3>\n",
    "For a given query:\n",
    "\n",
    "The generated answer is broken into smaller factual claims.\n",
    "\n",
    "Faithfulness = Number of claims supported by context / Total number of claims\n",
    "\n",
    "The final score is averaged over all queries.\n",
    "\n",
    "<h3> How it was calculated (implementation logic) </h3>\n",
    "1. The generated answer is split into individual factual statements.\n",
    "2. Each statement is checked against the retrieved context.\n",
    "3. If the statement is supported by the context, it is marked as faithful.\n",
    "4. The ratio of supported claims to total claims is computed.\n",
    "5. The final score is averaged across queries.\n",
    "\n",
    "\n",
    "<h3> Interpretation of my result </h3>\n",
    "Faithfulness = 0.9667\n",
    "This means that about 96.7% of the generated answer content is directly supported by retrieved documents.\n",
    "\n",
    "<b>What this tells us:</b>\n",
    "The model rarely hallucinates\n",
    "Answers are well grounded in the retrieved context\n",
    "The generation step is working correctly\n",
    "\n",
    "<h3>Benefit of this metric:</h3>\n",
    "It confirms that even when retrieval is noisy, the model is careful not to fabricate information and sticks closely to available evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca5c6a-d8fb-42de-8a06-5862d63df458",
   "metadata": {},
   "source": [
    "<h2>2.3 Innovative Evaluation (4 Marks)</h2>\n",
    "<h3>Demonstrate creativity through advanced techniques</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659409b-280c-458e-b84e-7ac6e00f911d",
   "metadata": {},
   "source": [
    "<h2>Ablation Studies:</h2> Compare dense-only, sparse-only, and hybrid performance. \n",
    "Experiment with different K, N, and RRF k values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc5428eb-4334-472b-8de1-affb4b5be43a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode- dense\n",
      "K- 7\n",
      "N- 5\n",
      "N- 10\n",
      "K- 10\n",
      "N- 5\n",
      "N- 10\n",
      "Mode- sparse\n",
      "K- 7\n",
      "N- 5\n",
      "N- 10\n",
      "K- 10\n",
      "N- 5\n",
      "N- 10\n",
      "Mode- hybrid\n",
      "K- 7\n",
      "N- 5\n",
      "N- 10\n",
      "K- 10\n",
      "N- 5\n",
      "N- 10\n",
      "     mode  top_k_dense  top_k_sparse  N_context  rrf_k  MRR  Precision@5  \\\n",
      "4  sparse            7             7          5    NaN  1.0          0.2   \n",
      "5  sparse            7             7         10    NaN  1.0          0.2   \n",
      "6  sparse           10            10          5    NaN  1.0          0.2   \n",
      "7  sparse           10            10         10    NaN  1.0          0.2   \n",
      "0   dense            7             7          5    NaN  0.9          0.2   \n",
      "1   dense            7             7         10    NaN  0.9          0.2   \n",
      "2   dense           10            10          5    NaN  0.9          0.2   \n",
      "3   dense           10            10         10    NaN  0.9          0.2   \n",
      "8  hybrid            7             7          5   10.0  0.9          0.2   \n",
      "9  hybrid            7             7          5   60.0  0.9          0.2   \n",
      "\n",
      "   avg_retrieval_time  \n",
      "4            0.211137  \n",
      "5            0.197740  \n",
      "6            0.218415  \n",
      "7            0.229194  \n",
      "0            3.509439  \n",
      "1            3.651056  \n",
      "2            3.608280  \n",
      "3            3.586978  \n",
      "8            3.948047  \n",
      "9            3.680605  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>top_k_dense</th>\n",
       "      <th>top_k_sparse</th>\n",
       "      <th>N_context</th>\n",
       "      <th>rrf_k</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Precision@5</th>\n",
       "      <th>avg_retrieval_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dense</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.509439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dense</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.651056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dense</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.608280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dense</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.586978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sparse</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.211137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sparse</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.197740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sparse</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.218415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sparse</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.229194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.948047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.680605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.701994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.729722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.717109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.678937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.665732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.145728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mode  top_k_dense  top_k_sparse  N_context  rrf_k  MRR  Precision@5  \\\n",
       "0    dense            7             7          5    NaN  0.9          0.2   \n",
       "1    dense            7             7         10    NaN  0.9          0.2   \n",
       "2    dense           10            10          5    NaN  0.9          0.2   \n",
       "3    dense           10            10         10    NaN  0.9          0.2   \n",
       "4   sparse            7             7          5    NaN  1.0          0.2   \n",
       "5   sparse            7             7         10    NaN  1.0          0.2   \n",
       "6   sparse           10            10          5    NaN  1.0          0.2   \n",
       "7   sparse           10            10         10    NaN  1.0          0.2   \n",
       "8   hybrid            7             7          5   10.0  0.9          0.2   \n",
       "9   hybrid            7             7          5   60.0  0.9          0.2   \n",
       "10  hybrid            7             7         10   10.0  0.9          0.2   \n",
       "11  hybrid            7             7         10   60.0  0.9          0.2   \n",
       "12  hybrid           10            10          5   10.0  0.9          0.2   \n",
       "13  hybrid           10            10          5   60.0  0.9          0.2   \n",
       "14  hybrid           10            10         10   10.0  0.9          0.2   \n",
       "15  hybrid           10            10         10   60.0  0.9          0.2   \n",
       "\n",
       "    avg_retrieval_time  \n",
       "0             3.509439  \n",
       "1             3.651056  \n",
       "2             3.608280  \n",
       "3             3.586978  \n",
       "4             0.211137  \n",
       "5             0.197740  \n",
       "6             0.218415  \n",
       "7             0.229194  \n",
       "8             3.948047  \n",
       "9             3.680605  \n",
       "10            3.701994  \n",
       "11            3.729722  \n",
       "12            3.717109  \n",
       "13            3.678937  \n",
       "14            3.665732  \n",
       "15            5.145728  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics.run_ablation import generate_matrix\n",
    "generate_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944531ff-9343-4410-a475-1b61b122a509",
   "metadata": {},
   "source": [
    "<h2> Error Analysis: </h2> Categorize failures (retrieval, generation, context issues) by question type with visualizations.\n",
    "\n",
    " - Loads questions from: data/questions_100.jsonl\n",
    " - Builds df (runs retrieval + generation once)\n",
    " - Classifies error_type: retrieval_failure / context_failure / generation_failure\n",
    " - Saves: data/eval/df_error_analysis.csv + error_summary.csv + 2 plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "574a75e4-5ce9-47ea-82ab-8ba3a3d0d6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done\n",
      "Saved df: data/eval\\df_error_analysis.csv\n",
      "Saved error summary: data/eval\\error_summary.csv\n",
      "Saved plots in: data/eval\n",
      "\n",
      "Error counts:\n",
      "error_type\n",
      "no_error           3\n",
      "context_failure    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from src.metrics.advance_error_analysis import main\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c45a2-5510-4bbc-8157-eafab4cd1af4",
   "metadata": {},
   "source": [
    "<h2> 2.4 Automated Pipeline </h2> \n",
    "\n",
    " Single-command pipeline (NO argparse):\n",
    " - loads questions from data/questions_100.jsonl\n",
    " - runs Hybrid RAG (dense + sparse + RRF)\n",
    " - computes MRR (URL-level), Precision@5, Faithfulness, latency\n",
    " - performs Error Analysis by question type\n",
    " - saves CSV/JSON + visualizations (PNG)\n",
    "\n",
    "Please follow these steps to run the pipeline\n",
    "\n",
    "Step 1: Open terminal and navigate to the project root (same level as src/ and data/):\n",
    "\n",
    "cd Sem3/Group_64_Hybrid_RAG\n",
    "\n",
    "Step 2: Execute the automated evaluation pipeline:\n",
    "\n",
    "python src/metrics/metrics_pipeline.py\n",
    "\n",
    "Step 3: The pipeline will:\n",
    "\n",
    "Load questions from:\n",
    "\n",
    "data/questions_100.jsonl\n",
    "\n",
    "Run:\n",
    "\n",
    "Hybrid retrieval (Dense + BM25 + RRF)\n",
    "\n",
    "Answer generation (Flan-T5)\n",
    "\n",
    "Metric computation (MRR, Precision@5, Faithfulness)\n",
    "\n",
    "Measure retrieval and total execution time per question\n",
    "\n",
    "Step 4: View Outputs\n",
    "\n",
    "All evaluation outputs are saved to:\n",
    "\n",
    "data/eval_run/\n",
    "\n",
    "\n",
    "This folder contains:\n",
    "\n",
    "results.csv → full internal evaluation dataframe\n",
    "\n",
    "results_table.csv → submission-ready results table\n",
    "\n",
    "summary.json → aggregated metric summary\n",
    "\n",
    "*.png → evaluation plots (metric distributions, error analysis)\n",
    "\n",
    "Metrics Summary Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01b872e9-905c-46d8-ada6-09000529fa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode- dense\n",
      "K- 10\n",
      "N- 5\n",
      "N- 10\n",
      "K- 30\n",
      "N- 5\n",
      "N- 10\n",
      "K- 50\n",
      "N- 5\n",
      "N- 10\n",
      "Mode- sparse\n",
      "K- 10\n",
      "N- 5\n",
      "N- 10\n",
      "K- 30\n",
      "N- 5\n",
      "N- 10\n",
      "K- 50\n",
      "N- 5\n",
      "N- 10\n",
      "Mode- hybrid\n",
      "K- 10\n",
      "N- 5\n",
      "N- 10\n",
      "K- 30\n",
      "N- 5\n",
      "N- 10\n",
      "K- 50\n",
      "N- 5\n",
      "N- 10\n",
      "      mode  top_k_dense  top_k_sparse  N_context  rrf_k       MRR  \\\n",
      "6   sparse           10            10          5    NaN  0.960000   \n",
      "7   sparse           10            10         10    NaN  0.960000   \n",
      "8   sparse           30            30          5    NaN  0.960000   \n",
      "9   sparse           30            30         10    NaN  0.960000   \n",
      "10  sparse           50            50          5    NaN  0.960000   \n",
      "11  sparse           50            50         10    NaN  0.960000   \n",
      "18  hybrid           30            30         10   10.0  0.925000   \n",
      "16  hybrid           30            30          5   10.0  0.925000   \n",
      "22  hybrid           50            50         10   10.0  0.924167   \n",
      "20  hybrid           50            50          5   10.0  0.924167   \n",
      "\n",
      "    Precision@5  avg_retrieval_time  \n",
      "6         0.242            0.199616  \n",
      "7         0.242            0.198680  \n",
      "8         0.242            0.200274  \n",
      "9         0.242            0.199029  \n",
      "10        0.242            0.205238  \n",
      "11        0.242            0.198144  \n",
      "18        0.244            3.941350  \n",
      "16        0.244            3.935415  \n",
      "22        0.242            3.820009  \n",
      "20        0.242            3.800351  \n",
      "Done. Outputs saved in: data/eval_run\n",
      "{\n",
      "  \"num_questions\": 100,\n",
      "  \"MRR_url_level\": 0.9162,\n",
      "  \"Precision@5_url_level\": 0.224,\n",
      "  \"Faithfulness_avg\": 0.9824,\n",
      "  \"Avg_retrieval_time_sec\": 4.1589,\n",
      "  \"Avg_total_time_sec\": 34.148,\n",
      "  \"Error_counts\": {\n",
      "    \"no_error\": 99,\n",
      "    \"retrieval_failure\": 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from src.metrics.metrics_pipeline import main\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adecc72-494c-4493-8fce-1117ae30758c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
